{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<center><b><H1> KAGGLE COMPETITION GNR 638 </H1></b></center>\r\n",
    "<center><b><H2> VINIT AWALE </H2></b></center>\r\n",
    "<center><b><H2> 18D070067 </H2></b></center>\r\n",
    "<center><b><H2> ELECTRICAL DUAL DEGREE </H2></b></center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the training folder to train and validation folders\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import splitfolders\r\n",
    "\r\n",
    "splitfolders.ratio('Dataset\\\\gnr6382021\\\\train', output='Dataset\\\\gnr6382021\\\\train', seed=1337, ratio=(.8, .2))  # 80% training, 20% validation"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Copying files: 500 files [00:00, 584.89 files/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After this the folder structure is adjusted to have the following structure:\r\n",
    "\r\n",
    "\r\n",
    "```\r\n",
    "Dataset\r\n",
    "├── train\r\n",
    "│   ├──basketball_court\r\n",
    "│   ├──bridge\r\n",
    "│   ├──crosswalk   \r\n",
    "│   ├──golf_course\r\n",
    "│   ├──oil_well\r\n",
    "│   ├──overpass\r\n",
    "│   ├──railway\r\n",
    "|   ├──runway\r\n",
    "|   ├──swimming_pool\r\n",
    "|   ├──tennis_court\r\n",
    "|── val\r\n",
    "│   ├──basketball_court\r\n",
    "│   ├──bridge\r\n",
    "│   ├──crosswalk\r\n",
    "│   ├──golf_course\r\n",
    "│   ├──oil_well\r\n",
    "│   ├──overpass\r\n",
    "│   ├──railway\r\n",
    "|   ├──runway\r\n",
    "|   ├──swimming_pool\r\n",
    "|   ├──tennis_court\r\n",
    "└── test\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "import glob\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "import torchvision\r\n",
    "from torchvision import transforms, utils\r\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\r\n",
    "import pathlib\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting the device"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transforms"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "transformer = transforms.Compose([\r\n",
    "    transforms.Resize((224,224)),\r\n",
    "    transforms.RandomHorizontalFlip(),    \r\n",
    "    transforms.ToTensor(),                  # make it into torch.Tensor and normalized into range [0, 1]\r\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # transform it into range [-1, 1]\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataloader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_path = \"Dataset\\\\train\"\r\n",
    "val_path = \"Dataset\\\\val\"\r\n",
    "\r\n",
    "\r\n",
    "train_loader = DataLoader(torchvision.datasets.ImageFolder(train_path, transform=transformer), batch_size=32, shuffle=True)\r\n",
    "val_loader = DataLoader(torchvision.datasets.ImageFolder(val_path, transform=transformer), batch_size=32, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "## Categories in the dataset\r\n",
    "root = pathlib.Path(train_path)\r\n",
    "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "classes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['basketball_court',\n",
       " 'bridge',\n",
       " 'crosswalk',\n",
       " 'golf_course',\n",
       " 'oil_well',\n",
       " 'overpass',\n",
       " 'railway',\n",
       " 'runway',\n",
       " 'swimming_pool',\n",
       " 'tennis_court']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "VGG_types = {\r\n",
    "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\r\n",
    "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\r\n",
    "    \"VGG16\": [64,64,\"M\",128,128,\"M\",256,256,256,\"M\",512,512,512,\"M\",512,512,512,\"M\"],\r\n",
    "    \"VGG19\": [64,64,\"M\",128,128,\"M\",256,256,256,256,\"M\",512,512,512,512,\"M\",512,512,512,512,\"M\"],\r\n",
    "}\r\n",
    "\r\n",
    "\r\n",
    "class VGG_net(nn.Module):\r\n",
    "    def __init__(self, in_channels, num_classes, type=\"VGG16\"):\r\n",
    "        super(VGG_net, self).__init__()\r\n",
    "        self.in_channels = in_channels\r\n",
    "        self.conv_layers = self.create_conv_layers(VGG_types[type])\r\n",
    "\r\n",
    "        self.fcs = nn.Sequential(\r\n",
    "            nn.Linear(512 * 7 * 7, 4096),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.5),\r\n",
    "            nn.Linear(4096, 4096),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.5),\r\n",
    "            nn.Linear(4096, num_classes),\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv_layers(x)\r\n",
    "        x = x.reshape(x.shape[0], -1)\r\n",
    "        x = self.fcs(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "    def create_conv_layers(self, architecture):\r\n",
    "        layers = []\r\n",
    "        in_channels = self.in_channels\r\n",
    "\r\n",
    "        for x in architecture:\r\n",
    "            if type(x) == int:\r\n",
    "                out_channels = x\r\n",
    "\r\n",
    "                layers += [\r\n",
    "                    nn.Conv2d(\r\n",
    "                        in_channels=in_channels,\r\n",
    "                        out_channels=out_channels,\r\n",
    "                        kernel_size=(3, 3),\r\n",
    "                        stride=(1, 1),\r\n",
    "                        padding=(1, 1),\r\n",
    "                    ),\r\n",
    "                    nn.BatchNorm2d(x),\r\n",
    "                    nn.ReLU(),\r\n",
    "                ]\r\n",
    "                in_channels = x\r\n",
    "            elif x == \"M\":\r\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\r\n",
    "\r\n",
    "        return nn.Sequential(*layers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "num_class = len(classes) # Number of classes in the dataset\r\n",
    "\r\n",
    "model = VGG_net(3,num_class,\"VGG16\").to(device)\r\n",
    "print(model)\r\n",
    "## N = 3 (Mini batch size)\r\n",
    "# x = torch.randn(3, 3, 224, 224).to(device)\r\n",
    "# print(model(x).shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VGG_net(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU()\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU()\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU()\n",
      "    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU()\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU()\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU()\n",
      "    (33): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU()\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU()\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU()\n",
      "    (43): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fcs): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimizer and Loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\r\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "num_epochs = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "## Calculate number of training and validation images\r\n",
    "num_train = len(glob.glob(train_path + \"/**/*.jpg\"))\r\n",
    "num_val = len(glob.glob(val_path + \"/**/*.jpg\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "print(\"Number of training images: {}\".format(num_train))\r\n",
    "print(\"Number of validation images: {}\".format(num_val))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training images: 500\n",
      "Number of validation images: 100\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model training and savint the best model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('gpu-pytorch': conda)"
  },
  "interpreter": {
   "hash": "3d1484f6a5966aacf1d005944f88794f1e4469136ed9878e517c1d6594061a94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}