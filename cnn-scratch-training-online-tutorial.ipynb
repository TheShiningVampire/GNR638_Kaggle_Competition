{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#Load libraries\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "import glob\r\n",
    "import torch.nn as nn\r\n",
    "from torchvision.transforms import transforms\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.optim import Adam\r\n",
    "from torch.autograd import Variable\r\n",
    "import torchvision\r\n",
    "import pathlib\r\n",
    "import math\r\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#checking for device\r\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "## Hyperparameters\r\n",
    "batch_size_ = 36\r\n",
    "num_epochs = 35\r\n",
    "size = 224"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "#Transforms\r\n",
    "transformer=transforms.Compose([\r\n",
    "    transforms.Resize((size,size)),\r\n",
    "    transforms.RandomHorizontalFlip(),\r\n",
    "    transforms.ColorJitter(brightness=0.8),\r\n",
    "    # transforms.RandomRotation(degrees=45),\r\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\r\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\r\n",
    "                        [0.5,0.5,0.5])\r\n",
    "])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "#Dataloader\r\n",
    "\r\n",
    "#Path for training and testing directory\r\n",
    "train_path='Dataset\\\\train'\r\n",
    "test_path='Dataset\\\\val'\r\n",
    "\r\n",
    "train_loader=DataLoader(\r\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\r\n",
    "    batch_size=batch_size_, shuffle=True\r\n",
    ")\r\n",
    "test_loader=DataLoader(\r\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\r\n",
    "    batch_size=batch_size_, shuffle=True\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "#categories\r\n",
    "root=pathlib.Path(train_path)\r\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "print(classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['basketball_court', 'bridge', 'crosswalk', 'golf_course', 'oil_well', 'overpass', 'railway', 'runway', 'swimming_pool', 'tennis_court']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "#CNN Network\r\n",
    "\r\n",
    "\r\n",
    "class ConvNet(nn.Module):\r\n",
    "    def __init__(self,num_classes):\r\n",
    "        super(ConvNet,self).__init__()\r\n",
    "        \r\n",
    "        #Output size after convolution filter\r\n",
    "        #((w-f+2P)/s) +1\r\n",
    "        \r\n",
    "        #Input shape= (256,3,256,256)\r\n",
    "        \r\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\r\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\r\n",
    "        self.relu1=nn.ReLU()\r\n",
    "        \r\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2)\r\n",
    "        \r\n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\r\n",
    "        self.relu2=nn.ReLU()\r\n",
    "        \r\n",
    "        \r\n",
    "        \r\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\r\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\r\n",
    "        self.relu3=nn.ReLU()\r\n",
    "        #Shape= (batch_size,32,128,128)\r\n",
    "\r\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\r\n",
    "\r\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\r\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=64)\r\n",
    "        self.relu4 = nn.ReLU()\r\n",
    "        # Shape = (batch_size,64,64,64)\r\n",
    "\r\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\r\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=128)\r\n",
    "        self.relu5 = nn.ReLU()\r\n",
    "        # Shape = (batch_size,128,64,64)\r\n",
    "\r\n",
    "        \r\n",
    "        self.fc=nn.Linear(in_features=128*64*64 ,out_features=num_classes)\r\n",
    "        \r\n",
    "        \r\n",
    "        \r\n",
    "        #Feed forwad function\r\n",
    "        \r\n",
    "    def forward(self,input):\r\n",
    "        output=self.conv1(input)\r\n",
    "        output=self.bn1(output)\r\n",
    "        output=self.relu1(output)\r\n",
    "            \r\n",
    "        output=self.pool1(output)\r\n",
    "            \r\n",
    "        output=self.conv2(output)\r\n",
    "        output=self.relu2(output)\r\n",
    "            \r\n",
    "        output=self.conv3(output)\r\n",
    "        output=self.bn3(output)\r\n",
    "        output=self.relu3(output)\r\n",
    "        \r\n",
    "        output=self.pool2(output)\r\n",
    "\r\n",
    "        output=self.conv4(output)\r\n",
    "        output=self.bn4(output)\r\n",
    "        output=self.relu4(output)\r\n",
    "\r\n",
    "        output=self.conv5(output)\r\n",
    "        output=self.bn5(output)\r\n",
    "        output=self.relu5(output)\r\n",
    "\r\n",
    "            \r\n",
    "        #Above output will be in matrix form, with shape (256,128,64,64)\r\n",
    "        \r\n",
    "        output=output.view(-1,128*64*64)\r\n",
    "            \r\n",
    "            \r\n",
    "        output=self.fc(output)\r\n",
    "            \r\n",
    "        return output\r\n",
    "            \r\n",
    "        \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "## VGG Network\r\n",
    "\r\n",
    "VGG_types = {\r\n",
    "    \"MyConv\": [16,\"M\",32,32,\"M\",64,64,\"M\",128,128,\"M\"],\r\n",
    "    \"MyVGG\" : [32,32,\"M\",64,64,\"M\",128,128,\"M\",256,256,\"M\"],\r\n",
    "    \"VGGmod\":[16, \"M\", 32, \"M\", 64,64, \"M\", 128,128, \"M\", 256, 256, \"M\",256,256, \"M\"],   \r\n",
    "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\r\n",
    "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\r\n",
    "    \"VGG16\": [64,64,\"M\",128,128,\"M\",256,256,256,\"M\",512,512,512,\"M\",512,512,512,\"M\"],\r\n",
    "    \"VGG19\": [64,64,\"M\",128,128,\"M\",256,256,256,256,\"M\",512,512,512,512,\"M\",512,512,512,512,\"M\"],\r\n",
    "}\r\n",
    "\r\n",
    "\r\n",
    "class VGG_net(nn.Module):\r\n",
    "    def __init__(self, in_channels, num_classes, type=\"VGG16\"):\r\n",
    "        super(VGG_net, self).__init__()\r\n",
    "        self.in_channels = in_channels\r\n",
    "        self.conv_layers = self.create_conv_layers(VGG_types[type])\r\n",
    "\r\n",
    "        self.fcs = nn.Sequential(\r\n",
    "            nn.Linear(512*7*7, num_classes),\r\n",
    "            # nn.ReLU(),\r\n",
    "            # nn.Dropout(p=0.5),\r\n",
    "            # nn.Linear(4096, num_classes),\r\n",
    "            # nn.ReLU(),\r\n",
    "            # nn.Dropout(p=0.5),\r\n",
    "            # nn.Linear(128, num_classes),\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv_layers(x)\r\n",
    "        x = x.reshape(x.shape[0], -1)\r\n",
    "        x = self.fcs(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "    def create_conv_layers(self, architecture):\r\n",
    "        layers = []\r\n",
    "        in_channels = self.in_channels\r\n",
    "\r\n",
    "        for x in architecture:\r\n",
    "            if type(x) == int:\r\n",
    "                out_channels = x\r\n",
    "\r\n",
    "                layers += [\r\n",
    "                    nn.Conv2d(\r\n",
    "                        in_channels=in_channels,\r\n",
    "                        out_channels=out_channels,\r\n",
    "                        kernel_size=(3, 3),\r\n",
    "                        stride=(1, 1),\r\n",
    "                        padding=(1, 1),\r\n",
    "                    ),\r\n",
    "                    nn.BatchNorm2d(x),\r\n",
    "                    nn.ReLU(),\r\n",
    "                ]\r\n",
    "                in_channels = x\r\n",
    "            elif x == \"M\":\r\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\r\n",
    "\r\n",
    "        return nn.Sequential(*layers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "## Inception Net\r\n",
    "\r\n",
    "class GoogLeNet(nn.Module):\r\n",
    "    def __init__(self, aux_logits=True, num_classes=10):\r\n",
    "        super(GoogLeNet, self).__init__()\r\n",
    "        assert aux_logits == True or aux_logits == False\r\n",
    "        self.aux_logits = aux_logits\r\n",
    "\r\n",
    "        # Write in_channels, etc, all explicit in self.conv1, rest will write to\r\n",
    "        # make everything as compact as possible, kernel_size=3 instead of (3,3)\r\n",
    "        self.conv1 = conv_block(\r\n",
    "            in_channels=3,\r\n",
    "            out_channels=64,\r\n",
    "            kernel_size=(7, 7),\r\n",
    "            stride=(2, 2),\r\n",
    "            padding=(3, 3),\r\n",
    "        )\r\n",
    "\r\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
    "        self.conv2 = conv_block(64, 192, kernel_size=3, stride=1, padding=1)\r\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
    "\r\n",
    "        # In this order: in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\r\n",
    "        self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\r\n",
    "        self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\r\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=(3, 3), stride=2, padding=1)\r\n",
    "\r\n",
    "        self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\r\n",
    "        self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\r\n",
    "        self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\r\n",
    "        self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\r\n",
    "        self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\r\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
    "\r\n",
    "        self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\r\n",
    "        self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\r\n",
    "\r\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\r\n",
    "        self.dropout = nn.Dropout(p=0.4)\r\n",
    "        self.fc1 = nn.Linear(1024, num_classes)\r\n",
    "\r\n",
    "        if self.aux_logits:\r\n",
    "            self.aux1 = InceptionAux(512, num_classes)\r\n",
    "            self.aux2 = InceptionAux(528, num_classes)\r\n",
    "        else:\r\n",
    "            self.aux1 = self.aux2 = None\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.maxpool1(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        # x = self.conv3(x)\r\n",
    "        x = self.maxpool2(x)\r\n",
    "\r\n",
    "        x = self.inception3a(x)\r\n",
    "        x = self.inception3b(x)\r\n",
    "        x = self.maxpool3(x)\r\n",
    "\r\n",
    "        x = self.inception4a(x)\r\n",
    "\r\n",
    "        # Auxiliary Softmax classifier 1\r\n",
    "        if self.aux_logits and self.training:\r\n",
    "            aux1 = self.aux1(x)\r\n",
    "\r\n",
    "        x = self.inception4b(x)\r\n",
    "        x = self.inception4c(x)\r\n",
    "        x = self.inception4d(x)\r\n",
    "\r\n",
    "        # Auxiliary Softmax classifier 2\r\n",
    "        if self.aux_logits and self.training:\r\n",
    "            aux2 = self.aux2(x)\r\n",
    "\r\n",
    "        x = self.inception4e(x)\r\n",
    "        x = self.maxpool4(x)\r\n",
    "        x = self.inception5a(x)\r\n",
    "        x = self.inception5b(x)\r\n",
    "        x = self.avgpool(x)\r\n",
    "        x = x.reshape(x.shape[0], -1)\r\n",
    "        x = self.dropout(x)\r\n",
    "        x = self.fc1(x)\r\n",
    "\r\n",
    "        if self.aux_logits and self.training:\r\n",
    "            return aux1, aux2, x\r\n",
    "        else:\r\n",
    "            return x\r\n",
    "\r\n",
    "\r\n",
    "class Inception_block(nn.Module):\r\n",
    "    def __init__(\r\n",
    "        self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\r\n",
    "    ):\r\n",
    "        super(Inception_block, self).__init__()\r\n",
    "        self.branch1 = conv_block(in_channels, out_1x1, kernel_size=(1, 1))\r\n",
    "\r\n",
    "        self.branch2 = nn.Sequential(\r\n",
    "            conv_block(in_channels, red_3x3, kernel_size=(1, 1)),\r\n",
    "            conv_block(red_3x3, out_3x3, kernel_size=(3, 3), padding=(1, 1)),\r\n",
    "        )\r\n",
    "\r\n",
    "        self.branch3 = nn.Sequential(\r\n",
    "            conv_block(in_channels, red_5x5, kernel_size=(1, 1)),\r\n",
    "            conv_block(red_5x5, out_5x5, kernel_size=(5, 5), padding=(2, 2)),\r\n",
    "        )\r\n",
    "\r\n",
    "        self.branch4 = nn.Sequential(\r\n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\r\n",
    "            conv_block(in_channels, out_1x1pool, kernel_size=(1, 1)),\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return torch.cat(\r\n",
    "            [self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1\r\n",
    "        )\r\n",
    "\r\n",
    "\r\n",
    "class InceptionAux(nn.Module):\r\n",
    "    def __init__(self, in_channels, num_classes):\r\n",
    "        super(InceptionAux, self).__init__()\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.dropout = nn.Dropout(p=0.7)\r\n",
    "        self.pool = nn.AvgPool2d(kernel_size=5, stride=3)\r\n",
    "        self.conv = conv_block(in_channels, 128, kernel_size=1)\r\n",
    "        self.fc1 = nn.Linear(2048, 1024)\r\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.pool(x)\r\n",
    "        x = self.conv(x)\r\n",
    "        x = x.reshape(x.shape[0], -1)\r\n",
    "        x = self.relu(self.fc1(x))\r\n",
    "        x = self.dropout(x)\r\n",
    "        x = self.fc2(x)\r\n",
    "\r\n",
    "        return x\r\n",
    "\r\n",
    "\r\n",
    "class conv_block(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\r\n",
    "        super(conv_block, self).__init__()\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\r\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.relu(self.batchnorm(self.conv(x)))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "## Resnet\r\n",
    "\r\n",
    "class block(nn.Module):\r\n",
    "    def __init__(\r\n",
    "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\r\n",
    "    ):\r\n",
    "        super(block, self).__init__()\r\n",
    "        self.expansion = 4\r\n",
    "        self.conv1 = nn.Conv2d(\r\n",
    "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\r\n",
    "        )\r\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\r\n",
    "        self.conv2 = nn.Conv2d(\r\n",
    "            intermediate_channels,\r\n",
    "            intermediate_channels,\r\n",
    "            kernel_size=3,\r\n",
    "            stride=stride,\r\n",
    "            padding=1,\r\n",
    "            bias=False\r\n",
    "        )\r\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\r\n",
    "        self.conv3 = nn.Conv2d(\r\n",
    "            intermediate_channels,\r\n",
    "            intermediate_channels * self.expansion,\r\n",
    "            kernel_size=1,\r\n",
    "            stride=1,\r\n",
    "            padding=0,\r\n",
    "            bias=False\r\n",
    "        )\r\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.identity_downsample = identity_downsample\r\n",
    "        self.stride = stride\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        identity = x.clone()\r\n",
    "\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.bn1(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = self.bn2(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.conv3(x)\r\n",
    "        x = self.bn3(x)\r\n",
    "\r\n",
    "        if self.identity_downsample is not None:\r\n",
    "            identity = self.identity_downsample(identity)\r\n",
    "\r\n",
    "        x += identity\r\n",
    "        x = self.relu(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "\r\n",
    "class ResNet(nn.Module):\r\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\r\n",
    "        super(ResNet, self).__init__()\r\n",
    "        self.in_channels = 64\r\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\r\n",
    "        self.bn1 = nn.BatchNorm2d(64)\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
    "\r\n",
    "        # Essentially the entire ResNet architecture are in these 4 lines below\r\n",
    "        self.layer1 = self._make_layer(\r\n",
    "            block, layers[0], intermediate_channels=64, stride=1\r\n",
    "        )\r\n",
    "        self.layer2 = self._make_layer(\r\n",
    "            block, layers[1], intermediate_channels=128, stride=2\r\n",
    "        )\r\n",
    "        self.layer3 = self._make_layer(\r\n",
    "            block, layers[2], intermediate_channels=256, stride=2\r\n",
    "        )\r\n",
    "        self.layer4 = self._make_layer(\r\n",
    "            block, layers[3], intermediate_channels=512, stride=2\r\n",
    "        )\r\n",
    "\r\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\r\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.bn1(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.maxpool(x)\r\n",
    "        x = self.layer1(x)\r\n",
    "        x = self.layer2(x)\r\n",
    "        x = self.layer3(x)\r\n",
    "        x = self.layer4(x)\r\n",
    "\r\n",
    "        x = self.avgpool(x)\r\n",
    "        x = x.reshape(x.shape[0], -1)\r\n",
    "        x = self.fc(x)\r\n",
    "\r\n",
    "        return x\r\n",
    "\r\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\r\n",
    "        identity_downsample = None\r\n",
    "        layers = []\r\n",
    "\r\n",
    "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\r\n",
    "        # we need to adapt the Identity (skip connection) so it will be able to be added\r\n",
    "        # to the layer that's ahead\r\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\r\n",
    "            identity_downsample = nn.Sequential(\r\n",
    "                nn.Conv2d(\r\n",
    "                    self.in_channels,\r\n",
    "                    intermediate_channels * 4,\r\n",
    "                    kernel_size=1,\r\n",
    "                    stride=stride,\r\n",
    "                    bias=False\r\n",
    "                ),\r\n",
    "                nn.BatchNorm2d(intermediate_channels * 4),\r\n",
    "            )\r\n",
    "\r\n",
    "        layers.append(\r\n",
    "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\r\n",
    "        )\r\n",
    "\r\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\r\n",
    "        self.in_channels = intermediate_channels * 4\r\n",
    "\r\n",
    "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\r\n",
    "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\r\n",
    "        # and also same amount of channels.\r\n",
    "        for i in range(num_residual_blocks - 1):\r\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\r\n",
    "\r\n",
    "        return nn.Sequential(*layers)\r\n",
    "\r\n",
    "\r\n",
    "def ResNet50(img_channel=3, num_classes=1000):\r\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\r\n",
    "\r\n",
    "\r\n",
    "def ResNet101(img_channel=3, num_classes=1000):\r\n",
    "    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\r\n",
    "\r\n",
    "\r\n",
    "def ResNet152(img_channel=3, num_classes=1000):\r\n",
    "    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "## Efficient Net\r\n",
    "\r\n",
    "from math import ceil\r\n",
    "\r\n",
    "base_model = [\r\n",
    "    # expand_ratio, channels, repeats, stride, kernel_size\r\n",
    "    [1, 16, 1, 1, 3],\r\n",
    "    [6, 24, 2, 2, 3],\r\n",
    "    [6, 40, 2, 2, 5],\r\n",
    "    [6, 80, 3, 2, 3],\r\n",
    "    [6, 112, 3, 1, 5],\r\n",
    "    [6, 192, 4, 2, 5],\r\n",
    "    [6, 320, 1, 1, 3],\r\n",
    "]\r\n",
    "\r\n",
    "phi_values = {\r\n",
    "    # tuple of: (phi_value, resolution, drop_rate)\r\n",
    "    \"b0\": (0, 224, 0.2),  # alpha, beta, gamma, depth = alpha ** phi\r\n",
    "    \"b1\": (0.5, 240, 0.2),\r\n",
    "    \"b2\": (1, 260, 0.3),\r\n",
    "    \"b3\": (2, 300, 0.3),\r\n",
    "    \"b4\": (3, 380, 0.4),\r\n",
    "    \"b5\": (4, 456, 0.4),\r\n",
    "    \"b6\": (5, 528, 0.5),\r\n",
    "    \"b7\": (6, 600, 0.5),\r\n",
    "}\r\n",
    "\r\n",
    "class CNNBlock(nn.Module):\r\n",
    "    def __init__(\r\n",
    "            self, in_channels, out_channels, kernel_size, stride, padding, groups=1\r\n",
    "    ):\r\n",
    "        super(CNNBlock, self).__init__()\r\n",
    "        self.cnn = nn.Conv2d(\r\n",
    "            in_channels,\r\n",
    "            out_channels,\r\n",
    "            kernel_size,\r\n",
    "            stride,\r\n",
    "            padding,\r\n",
    "            groups=groups,\r\n",
    "            bias=False,\r\n",
    "        )\r\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\r\n",
    "        self.silu = nn.SiLU() # SiLU <-> Swish\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.silu(self.bn(self.cnn(x)))\r\n",
    "\r\n",
    "class SqueezeExcitation(nn.Module):\r\n",
    "    def __init__(self, in_channels, reduced_dim):\r\n",
    "        super(SqueezeExcitation, self).__init__()\r\n",
    "        self.se = nn.Sequential(\r\n",
    "            nn.AdaptiveAvgPool2d(1), # C x H x W -> C x 1 x 1\r\n",
    "            nn.Conv2d(in_channels, reduced_dim, 1),\r\n",
    "            nn.SiLU(),\r\n",
    "            nn.Conv2d(reduced_dim, in_channels, 1),\r\n",
    "            nn.Sigmoid(),\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return x * self.se(x)\r\n",
    "\r\n",
    "class InvertedResidualBlock(nn.Module):\r\n",
    "    def __init__(\r\n",
    "            self,\r\n",
    "            in_channels,\r\n",
    "            out_channels,\r\n",
    "            kernel_size,\r\n",
    "            stride,\r\n",
    "            padding,\r\n",
    "            expand_ratio,\r\n",
    "            reduction=4, # squeeze excitation\r\n",
    "            survival_prob=0.8, # for stochastic depth\r\n",
    "    ):\r\n",
    "        super(InvertedResidualBlock, self).__init__()\r\n",
    "        self.survival_prob = 0.8\r\n",
    "        self.use_residual = in_channels == out_channels and stride == 1\r\n",
    "        hidden_dim = in_channels * expand_ratio\r\n",
    "        self.expand = in_channels != hidden_dim\r\n",
    "        reduced_dim = int(in_channels / reduction)\r\n",
    "\r\n",
    "        if self.expand:\r\n",
    "            self.expand_conv = CNNBlock(\r\n",
    "                in_channels, hidden_dim, kernel_size=3, stride=1, padding=1,\r\n",
    "            )\r\n",
    "\r\n",
    "        self.conv = nn.Sequential(\r\n",
    "            CNNBlock(\r\n",
    "                hidden_dim, hidden_dim, kernel_size, stride, padding, groups=hidden_dim,\r\n",
    "            ),\r\n",
    "            SqueezeExcitation(hidden_dim, reduced_dim),\r\n",
    "            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\r\n",
    "            nn.BatchNorm2d(out_channels),\r\n",
    "        )\r\n",
    "\r\n",
    "    def stochastic_depth(self, x):\r\n",
    "        if not self.training:\r\n",
    "            return x\r\n",
    "\r\n",
    "        binary_tensor = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob\r\n",
    "        return torch.div(x, self.survival_prob) * binary_tensor\r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        x = self.expand_conv(inputs) if self.expand else inputs\r\n",
    "\r\n",
    "        if self.use_residual:\r\n",
    "            return self.stochastic_depth(self.conv(x)) + inputs\r\n",
    "        else:\r\n",
    "            return self.conv(x)\r\n",
    "\r\n",
    "\r\n",
    "class EfficientNet(nn.Module):\r\n",
    "    def __init__(self, version, num_classes):\r\n",
    "        super(EfficientNet, self).__init__()\r\n",
    "        width_factor, depth_factor, dropout_rate = self.calculate_factors(version)\r\n",
    "        last_channels = ceil(1280 * width_factor)\r\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\r\n",
    "        self.features = self.create_features(width_factor, depth_factor, last_channels)\r\n",
    "        self.classifier = nn.Sequential(\r\n",
    "            nn.Dropout(dropout_rate),\r\n",
    "            nn.Linear(last_channels, num_classes),\r\n",
    "        )\r\n",
    "\r\n",
    "    def calculate_factors(self, version, alpha=1.2, beta=1.1):\r\n",
    "        phi, res, drop_rate = phi_values[version]\r\n",
    "        depth_factor = alpha ** phi\r\n",
    "        width_factor = beta ** phi\r\n",
    "        return width_factor, depth_factor, drop_rate\r\n",
    "\r\n",
    "    def create_features(self, width_factor, depth_factor, last_channels):\r\n",
    "        channels = int(32 * width_factor)\r\n",
    "        features = [CNNBlock(3, channels, 3, stride=2, padding=1)]\r\n",
    "        in_channels = channels\r\n",
    "\r\n",
    "        for expand_ratio, channels, repeats, stride, kernel_size in base_model:\r\n",
    "            out_channels = 4*ceil(int(channels*width_factor) / 4)\r\n",
    "            layers_repeats = ceil(repeats * depth_factor)\r\n",
    "\r\n",
    "            for layer in range(layers_repeats):\r\n",
    "                features.append(\r\n",
    "                    InvertedResidualBlock(\r\n",
    "                        in_channels,\r\n",
    "                        out_channels,\r\n",
    "                        expand_ratio=expand_ratio,\r\n",
    "                        stride = stride if layer == 0 else 1,\r\n",
    "                        kernel_size=kernel_size,\r\n",
    "                        padding=kernel_size//2, # if k=1:pad=0, k=3:pad=1, k=5:pad=2\r\n",
    "                    )\r\n",
    "                )\r\n",
    "                in_channels = out_channels\r\n",
    "\r\n",
    "        features.append(\r\n",
    "            CNNBlock(in_channels, last_channels, kernel_size=1, stride=1, padding=0)\r\n",
    "        )\r\n",
    "\r\n",
    "        return nn.Sequential(*features)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.pool(self.features(x))\r\n",
    "        return self.classifier(x.view(x.shape[0], -1))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# model = VGG_net(3, len(classes) , \"VGG13\").to(device)     #!All models out of race \r\n",
    "\r\n",
    "model = GoogLeNet(aux_logits=False, num_classes=len(classes)).to(device)  #* Without logits works best\r\n",
    "\r\n",
    "# model = GoogLeNet(aux_logits=True, num_classes=len(classes)).to(device)  #* Without logits works best\r\n",
    "\r\n",
    "# model = EfficientNet(version= \"b0\" ,num_classes=len(classes)).to(device)   #* Useless Model\r\n",
    "\r\n",
    "# model = ResNet101(img_channel=3, num_classes=len(classes)).to(device) #!All models out of race\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observations\r\n",
    "\r\n",
    "For GoogLeNet \r\n",
    "- batch size of 32 and 20 epochs \r\n",
    "  - the training accuracy is about 0.98. It gives tennis courts and basket ball courts as Runway. 117 --> Crosswalk, 199--> Runway.\r\n",
    "\r\n",
    "- Batch size 40 out of memory\r\n",
    "\r\n",
    "- Batch size 36, epochs 20 \r\n",
    "  - training accuracy 0.99. Again gives tennis courts and basket ball courts as Runway. 117 --> basketball_court, 199--> Runway.\r\n",
    "  - Better than batch size 32.\r\n",
    "\r\n",
    "- Batch size 36, epochs 30\r\n",
    "  - training accuracy 1. Gives tennis courts and basket ball courts correct. 117 --> Railway, 120--> railway 199--> Runway.\r\n",
    "  - Maybe the model is overfitting.\r\n",
    "\r\n",
    "- With more Data Augmentation\r\n",
    "  - Batch size 32, epochs 30\r\n",
    "   - Seems training did not complete\r\n",
    "   - Wrong output for images with shadows.\r\n",
    "\r\n",
    "  - added image crop, epochs 50\r\n",
    "   - - Shadows issue seems to be resoloved.\r\n",
    "   - - But Oilwells not classified properly.\r\n",
    "   - - 117--> Tennis_court, 120 --> Tennis_court, 199 --> Basketball_court. # All are correct.\r\n",
    "   - - Seems to me that random crop is not correct.\r\n",
    "  \r\n",
    "  - Removed image crop, epochs 50\r\n",
    "   - - Oilwells not classified properly again.\r\n",
    "   - - Seems crop is not the issue\r\n",
    "   - - The issue lies with higher epochs. \r\n",
    "   - - 117--> Basketball_court, 120 --> Basketball_court, 199 --> Crosswalk. \r\n",
    "\r\n",
    "  - Epochs 40\r\n",
    "  - - Didn't get so good results\r\n",
    "  - - 117--> Basketball_court, 120 --> Tennis_court, 199 --> Crosswalk. # Cross walk is wrong.\r\n",
    "\r\n",
    "  - CenterCrop instead of RandomCrop\r\n",
    "  - - Not so good results\r\n",
    "  - - Oilwells issue persists.\r\n",
    "  - - 117--> Basketball_court, 120 --> Tennis_court, 199 --> Basketball_court. # All correct\r\n",
    "  - - Seems training did not complete\r\n",
    "\r\n",
    "  Observation: Increasing epochs is making oilwell detection more difficult.\r\n",
    "\r\n",
    "For GoogleNet with Aux Logits True\r\n",
    "- batch size of 36 and 30 epochs\r\n",
    "  - Pretty bad model. Gives bridge as Basketball court. 117--> Basket ball court ,120--> Railway ,199--> Runway\r\n",
    "\r\n",
    "- batch size of 32 and 20 epochs\r\n",
    "  - Better than batch size 36 and 30 epochs. Good classification for basketball court and tennis court. 117 -->oilwell, 120 --> Railway, 199 --> Basketball court.\r\n",
    "\r\n",
    "For EffecientNet \r\n",
    "- batch size of 32 and 20 epochs\r\n",
    "  - out of memory\r\n",
    "\r\n",
    "- batch size of 16 and 20 epochs\r\n",
    "  - Didn't complete training.\r\n",
    "\r\n",
    "- batch size of 16 and 30 epochs\r\n",
    "  - Pretty bad model. Training accuracy is 1. Oil well not learnt at all. Lots of overpass and Crosswalk.\r\n",
    "   Gives bridge as Basketball court. 117--> Overpass ,120--> Overpass ,199--> Crosswalk"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "#Optmizer and loss function\r\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\r\n",
    "loss_function=nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "#calculating the size of training and testing images\r\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\r\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "print(train_count,test_count)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "500 100\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "#Model training and saving best model \r\n",
    "\r\n",
    "best_accuracy=0.0\r\n",
    "\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    \r\n",
    "    #Evaluation and training on training dataset\r\n",
    "    model.train()\r\n",
    "    train_accuracy=0.0\r\n",
    "    train_loss=0.0\r\n",
    "    \r\n",
    "    for i, (images,labels) in enumerate(train_loader):\r\n",
    "        if torch.cuda.is_available():\r\n",
    "            images=Variable(images.cuda())\r\n",
    "            labels=Variable(labels.cuda())\r\n",
    "            \r\n",
    "        optimizer.zero_grad()\r\n",
    "        \r\n",
    "        outputs=model(images)\r\n",
    "        loss=loss_function(outputs,labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        \r\n",
    "        train_loss+= loss.cpu().data*images.size(0)\r\n",
    "        _,prediction=torch.max(outputs.data,1)\r\n",
    "        \r\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\r\n",
    "        \r\n",
    "    train_accuracy=train_accuracy/train_count\r\n",
    "    train_loss=train_loss/train_count\r\n",
    "    \r\n",
    "    \r\n",
    "    # Evaluation on testing dataset\r\n",
    "    model.eval()\r\n",
    "    \r\n",
    "    test_accuracy=0.0\r\n",
    "    for i, (images,labels) in enumerate(test_loader):\r\n",
    "        if torch.cuda.is_available():\r\n",
    "            images=Variable(images.cuda())\r\n",
    "            labels=Variable(labels.cuda())\r\n",
    "            \r\n",
    "        outputs=model(images)\r\n",
    "        _,prediction=torch.max(outputs.data,1)\r\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\r\n",
    "    \r\n",
    "    test_accuracy=test_accuracy/test_count\r\n",
    "    \r\n",
    "    \r\n",
    "    print('Epoch: '+str(epoch+1)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\r\n",
    "    \r\n",
    "    #Save the best model\r\n",
    "    if test_accuracy>=best_accuracy:\r\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\r\n",
    "        best_accuracy=test_accuracy\r\n",
    "    \r\n",
    "       \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1 Train Loss: tensor(1.9219) Train Accuracy: 0.3 Test Accuracy: 0.1\n",
      "Epoch: 2 Train Loss: tensor(1.3685) Train Accuracy: 0.51 Test Accuracy: 0.23\n",
      "Epoch: 3 Train Loss: tensor(1.1703) Train Accuracy: 0.59 Test Accuracy: 0.44\n",
      "Epoch: 4 Train Loss: tensor(0.9829) Train Accuracy: 0.658 Test Accuracy: 0.59\n",
      "Epoch: 5 Train Loss: tensor(1.0385) Train Accuracy: 0.658 Test Accuracy: 0.52\n",
      "Epoch: 6 Train Loss: tensor(0.9253) Train Accuracy: 0.68 Test Accuracy: 0.34\n",
      "Epoch: 7 Train Loss: tensor(0.8724) Train Accuracy: 0.702 Test Accuracy: 0.47\n",
      "Epoch: 8 Train Loss: tensor(0.7218) Train Accuracy: 0.75 Test Accuracy: 0.6\n",
      "Epoch: 9 Train Loss: tensor(0.6709) Train Accuracy: 0.748 Test Accuracy: 0.75\n",
      "Epoch: 10 Train Loss: tensor(0.8583) Train Accuracy: 0.696 Test Accuracy: 0.49\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "checkpoint = torch.load('best_checkpoint.model')\r\n",
    "model.load_state_dict(checkpoint)\r\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): conv_block(\n",
       "    (relu): ReLU()\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv2): conv_block(\n",
       "    (relu): ReLU()\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception3a): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception4a): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception5a): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Transforms\r\n",
    "transformer=transforms.Compose([\r\n",
    "    transforms.Resize((size,size)),\r\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\r\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\r\n",
    "                        [0.5,0.5,0.5])\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Making predictions\r\n",
    "from PIL import Image\r\n",
    "from io import open\r\n",
    "\r\n",
    "\r\n",
    "def prediction(path, transform):\r\n",
    "    image=Image.open(path)\r\n",
    "    image_tensor=transformer(image).float()\r\n",
    "    image_tensor=image_tensor.unsqueeze_(0)\r\n",
    "    image_tensor=image_tensor.to(device)\r\n",
    "    output=model(image_tensor)\r\n",
    "    _,prediction=torch.max(output.data,1)\r\n",
    "    return classes[prediction[0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_path = \"Dataset\\\\test\"\r\n",
    "image_path=glob.glob(test_path+'/*.jpg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions={}\r\n",
    "for i,path in enumerate(image_path):\r\n",
    "    predictions[path[len(test_path)+1:]]=prediction(path,transformer)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'101.jpg': 'oil_well',\n",
       " '102.jpg': 'tennis_court',\n",
       " '103.jpg': 'crosswalk',\n",
       " '104.jpg': 'basketball_court',\n",
       " '105.jpg': 'basketball_court',\n",
       " '106.jpg': 'overpass',\n",
       " '107.jpg': 'tennis_court',\n",
       " '108.jpg': 'golf_course',\n",
       " '109.jpg': 'bridge',\n",
       " '110.jpg': 'bridge',\n",
       " '111.jpg': 'basketball_court',\n",
       " '112.jpg': 'basketball_court',\n",
       " '113.jpg': 'oil_well',\n",
       " '114.jpg': 'overpass',\n",
       " '115.jpg': 'runway',\n",
       " '116.jpg': 'swimming_pool',\n",
       " '117.jpg': 'basketball_court',\n",
       " '118.jpg': 'basketball_court',\n",
       " '119.jpg': 'runway',\n",
       " '120.jpg': 'tennis_court',\n",
       " '121.jpg': 'basketball_court',\n",
       " '122.jpg': 'bridge',\n",
       " '123.jpg': 'overpass',\n",
       " '124.jpg': 'golf_course',\n",
       " '125.jpg': 'crosswalk',\n",
       " '126.jpg': 'overpass',\n",
       " '127.jpg': 'basketball_court',\n",
       " '128.jpg': 'basketball_court',\n",
       " '129.jpg': 'basketball_court',\n",
       " '130.jpg': 'crosswalk',\n",
       " '131.jpg': 'golf_course',\n",
       " '132.jpg': 'basketball_court',\n",
       " '133.jpg': 'crosswalk',\n",
       " '134.jpg': 'runway',\n",
       " '135.jpg': 'bridge',\n",
       " '136.jpg': 'golf_course',\n",
       " '137.jpg': 'bridge',\n",
       " '138.jpg': 'bridge',\n",
       " '139.jpg': 'overpass',\n",
       " '140.jpg': 'golf_course',\n",
       " '141.jpg': 'tennis_court',\n",
       " '142.jpg': 'tennis_court',\n",
       " '143.jpg': 'basketball_court',\n",
       " '144.jpg': 'golf_course',\n",
       " '145.jpg': 'basketball_court',\n",
       " '146.jpg': 'golf_course',\n",
       " '147.jpg': 'tennis_court',\n",
       " '148.jpg': 'oil_well',\n",
       " '149.jpg': 'basketball_court',\n",
       " '150.jpg': 'basketball_court',\n",
       " '151.jpg': 'runway',\n",
       " '152.jpg': 'runway',\n",
       " '153.jpg': 'basketball_court',\n",
       " '154.jpg': 'overpass',\n",
       " '155.jpg': 'basketball_court',\n",
       " '156.jpg': 'golf_course',\n",
       " '157.jpg': 'tennis_court',\n",
       " '158.jpg': 'crosswalk',\n",
       " '159.jpg': 'railway',\n",
       " '160.jpg': 'bridge',\n",
       " '161.jpg': 'tennis_court',\n",
       " '162.jpg': 'overpass',\n",
       " '163.jpg': 'golf_course',\n",
       " '164.jpg': 'bridge',\n",
       " '165.jpg': 'basketball_court',\n",
       " '166.jpg': 'golf_course',\n",
       " '167.jpg': 'runway',\n",
       " '168.jpg': 'swimming_pool',\n",
       " '169.jpg': 'golf_course',\n",
       " '170.jpg': 'tennis_court',\n",
       " '171.jpg': 'oil_well',\n",
       " '172.jpg': 'overpass',\n",
       " '173.jpg': 'swimming_pool',\n",
       " '174.jpg': 'bridge',\n",
       " '175.jpg': 'runway',\n",
       " '176.jpg': 'overpass',\n",
       " '177.jpg': 'railway',\n",
       " '178.jpg': 'basketball_court',\n",
       " '179.jpg': 'crosswalk',\n",
       " '180.jpg': 'golf_course',\n",
       " '181.jpg': 'bridge',\n",
       " '182.jpg': 'golf_course',\n",
       " '183.jpg': 'bridge',\n",
       " '184.jpg': 'runway',\n",
       " '185.jpg': 'overpass',\n",
       " '186.jpg': 'tennis_court',\n",
       " '187.jpg': 'runway',\n",
       " '188.jpg': 'crosswalk',\n",
       " '189.jpg': 'oil_well',\n",
       " '190.jpg': 'basketball_court',\n",
       " '191.jpg': 'overpass',\n",
       " '192.jpg': 'bridge',\n",
       " '193.jpg': 'overpass',\n",
       " '194.jpg': 'swimming_pool',\n",
       " '195.jpg': 'basketball_court',\n",
       " '196.jpg': 'railway',\n",
       " '197.jpg': 'basketball_court',\n",
       " '198.jpg': 'golf_course',\n",
       " '199.jpg': 'tennis_court',\n",
       " '200.jpg': 'runway'}"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "label_dict = {\r\n",
    "    \"basketball_court\": 1, \r\n",
    "    \"bridge\":2, \r\n",
    "    \"crosswalk\":3, \r\n",
    "    \"golf_course\":4, \r\n",
    "    \"oil_well\":5, \r\n",
    "    \"overpass\":6, \r\n",
    "    \"railway\":7, \r\n",
    "    \"runway\":8, \r\n",
    "    \"swimming_pool\":9, \r\n",
    "    \"tennis_court\":10\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Convert the predictions to labels from label_dict\r\n",
    "predictions_labels={}\r\n",
    "for key,value in predictions.items():\r\n",
    "    predictions_labels[key]=label_dict[value]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'101.jpg': 5,\n",
       " '102.jpg': 10,\n",
       " '103.jpg': 3,\n",
       " '104.jpg': 1,\n",
       " '105.jpg': 1,\n",
       " '106.jpg': 6,\n",
       " '107.jpg': 10,\n",
       " '108.jpg': 4,\n",
       " '109.jpg': 2,\n",
       " '110.jpg': 2,\n",
       " '111.jpg': 1,\n",
       " '112.jpg': 1,\n",
       " '113.jpg': 5,\n",
       " '114.jpg': 6,\n",
       " '115.jpg': 8,\n",
       " '116.jpg': 9,\n",
       " '117.jpg': 1,\n",
       " '118.jpg': 1,\n",
       " '119.jpg': 8,\n",
       " '120.jpg': 10,\n",
       " '121.jpg': 1,\n",
       " '122.jpg': 2,\n",
       " '123.jpg': 6,\n",
       " '124.jpg': 4,\n",
       " '125.jpg': 3,\n",
       " '126.jpg': 6,\n",
       " '127.jpg': 1,\n",
       " '128.jpg': 1,\n",
       " '129.jpg': 1,\n",
       " '130.jpg': 3,\n",
       " '131.jpg': 4,\n",
       " '132.jpg': 1,\n",
       " '133.jpg': 3,\n",
       " '134.jpg': 8,\n",
       " '135.jpg': 2,\n",
       " '136.jpg': 4,\n",
       " '137.jpg': 2,\n",
       " '138.jpg': 2,\n",
       " '139.jpg': 6,\n",
       " '140.jpg': 4,\n",
       " '141.jpg': 10,\n",
       " '142.jpg': 10,\n",
       " '143.jpg': 1,\n",
       " '144.jpg': 4,\n",
       " '145.jpg': 1,\n",
       " '146.jpg': 4,\n",
       " '147.jpg': 10,\n",
       " '148.jpg': 5,\n",
       " '149.jpg': 1,\n",
       " '150.jpg': 1,\n",
       " '151.jpg': 8,\n",
       " '152.jpg': 8,\n",
       " '153.jpg': 1,\n",
       " '154.jpg': 6,\n",
       " '155.jpg': 1,\n",
       " '156.jpg': 4,\n",
       " '157.jpg': 10,\n",
       " '158.jpg': 3,\n",
       " '159.jpg': 7,\n",
       " '160.jpg': 2,\n",
       " '161.jpg': 10,\n",
       " '162.jpg': 6,\n",
       " '163.jpg': 4,\n",
       " '164.jpg': 2,\n",
       " '165.jpg': 1,\n",
       " '166.jpg': 4,\n",
       " '167.jpg': 8,\n",
       " '168.jpg': 9,\n",
       " '169.jpg': 4,\n",
       " '170.jpg': 10,\n",
       " '171.jpg': 5,\n",
       " '172.jpg': 6,\n",
       " '173.jpg': 9,\n",
       " '174.jpg': 2,\n",
       " '175.jpg': 8,\n",
       " '176.jpg': 6,\n",
       " '177.jpg': 7,\n",
       " '178.jpg': 1,\n",
       " '179.jpg': 3,\n",
       " '180.jpg': 4,\n",
       " '181.jpg': 2,\n",
       " '182.jpg': 4,\n",
       " '183.jpg': 2,\n",
       " '184.jpg': 8,\n",
       " '185.jpg': 6,\n",
       " '186.jpg': 10,\n",
       " '187.jpg': 8,\n",
       " '188.jpg': 3,\n",
       " '189.jpg': 5,\n",
       " '190.jpg': 1,\n",
       " '191.jpg': 6,\n",
       " '192.jpg': 2,\n",
       " '193.jpg': 6,\n",
       " '194.jpg': 9,\n",
       " '195.jpg': 1,\n",
       " '196.jpg': 7,\n",
       " '197.jpg': 1,\n",
       " '198.jpg': 4,\n",
       " '199.jpg': 10,\n",
       " '200.jpg': 8}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting the predictions to CSV format"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert predictions to dataframe\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# Make a dataframe with the predictions with column names as ImageID and LabelID\r\n",
    "predictions_df = pd.DataFrame.from_dict(predictions_labels, orient='index')\r\n",
    "\r\n",
    "# Removing the .jpg from the file names\r\n",
    "predictions_df.index=predictions_df.index.str.replace('.jpg','')\r\n",
    "\r\n",
    "# Naming the columns as ImageID and Label\r\n",
    "predictions_df.reset_index(level=0, inplace=True)\r\n",
    "predictions_df.columns = ['ImageID', 'LabelID']\r\n",
    "\r\n",
    "# Removing the index from the dataframe\r\n",
    "predictions_df.reset_index(drop= True, inplace=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Vinit\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>LabelID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>196</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>199</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageID  LabelID\n",
       "0      101        5\n",
       "1      102       10\n",
       "2      103        3\n",
       "3      104        1\n",
       "4      105        1\n",
       "..     ...      ...\n",
       "95     196        7\n",
       "96     197        1\n",
       "97     198        4\n",
       "98     199       10\n",
       "99     200        8\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Saving the predictions to csv\r\n",
    "predictions_df.to_csv('18D070067.csv',index=False)   #18D070067.csv is the name of the csv file and the index have been dropped"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hence, the implementation of the model is complete and the predictions are converted to CSV format."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('gpu-pytorch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "3d1484f6a5966aacf1d005944f88794f1e4469136ed9878e517c1d6594061a94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}