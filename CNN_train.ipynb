{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<center><b><H1> KAGGLE COMPETITION GNR 638 </H1></b></center>\r\n",
    "<center><b><H2> VINIT AWALE </H2></b></center>\r\n",
    "<center><b><H2> 18D070067 </H2></b></center>\r\n",
    "<center><b><H2> ELECTRICAL DUAL DEGREE </H2></b></center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the training folder to train and validation folders\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#import splitfolders\r\n",
    "\r\n",
    "#splitfolders.ratio('Dataset\\\\gnr6382021\\\\train', output='Dataset\\\\gnr6382021\\\\train', seed=1337, ratio=(.8, .2))  # 80% training, 20% validation"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After this the folder structure is adjusted to have the following structure:\r\n",
    "\r\n",
    "\r\n",
    "```\r\n",
    "Dataset\r\n",
    "├── train\r\n",
    "│   ├──basketball_court\r\n",
    "│   ├──bridge\r\n",
    "│   ├──crosswalk   \r\n",
    "│   ├──golf_course\r\n",
    "│   ├──oil_well\r\n",
    "│   ├──overpass\r\n",
    "│   ├──railway\r\n",
    "|   ├──runway\r\n",
    "|   ├──swimming_pool\r\n",
    "|   ├──tennis_court\r\n",
    "|── val\r\n",
    "│   ├──basketball_court\r\n",
    "│   ├──bridge\r\n",
    "│   ├──crosswalk\r\n",
    "│   ├──golf_course\r\n",
    "│   ├──oil_well\r\n",
    "│   ├──overpass\r\n",
    "│   ├──railway\r\n",
    "|   ├──runway\r\n",
    "|   ├──swimming_pool\r\n",
    "|   ├──tennis_court\r\n",
    "└── test\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Load libraries\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "import glob\r\n",
    "import torch.nn as nn\r\n",
    "from torchvision.transforms import transforms\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.optim import Adam\r\n",
    "from torch.autograd import Variable\r\n",
    "import torchvision\r\n",
    "import pathlib\r\n",
    "import math\r\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#checking for device\r\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "## Hyperparameters\r\n",
    "batch_size_ = 32\r\n",
    "num_epochs = 30\r\n",
    "size = 224"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Augmentation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#Transforms\r\n",
    "# For the submission with best accuracy only RandomHorizontalFlip was used for data augmentation\r\n",
    "\r\n",
    "transformer=transforms.Compose([\r\n",
    "    transforms.Resize((size,size)),\r\n",
    "    transforms.RandomHorizontalFlip(),\r\n",
    "    # transforms.RandomVerticalFlip(p = 0.1),\r\n",
    "    # transforms.ColorJitter(brightness=0.9),\r\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\r\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\r\n",
    "                        [0.5,0.5,0.5])\r\n",
    "])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataloader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\r\n",
    "\r\n",
    "#Path for training and testing directory\r\n",
    "train_path='Dataset\\\\train'\r\n",
    "test_path='Dataset\\\\val'\r\n",
    "\r\n",
    "train_loader=DataLoader(\r\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\r\n",
    "    batch_size=batch_size_, shuffle=True\r\n",
    ")\r\n",
    "test_loader=DataLoader(\r\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\r\n",
    "    batch_size=batch_size_, shuffle=True\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#categories\r\n",
    "root=pathlib.Path(train_path)\r\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['basketball_court', 'bridge', 'crosswalk', 'golf_course', 'oil_well', 'overpass', 'railway', 'runway', 'swimming_pool', 'tennis_court']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the Neural Network Architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#CNN Network\r\n",
    "\r\n",
    "\r\n",
    "class ConvNet(nn.Module):\r\n",
    "    def __init__(self,num_classes):\r\n",
    "        super(ConvNet,self).__init__()\r\n",
    "        \r\n",
    "        #Output size after convolution filter\r\n",
    "        #((w-f+2P)/s) +1\r\n",
    "        \r\n",
    "        #Input shape= (256,3,256,256)\r\n",
    "        \r\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\r\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\r\n",
    "        self.relu1=nn.ReLU()\r\n",
    "        \r\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2)\r\n",
    "        \r\n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\r\n",
    "        self.relu2=nn.ReLU()\r\n",
    "        \r\n",
    "        \r\n",
    "        \r\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\r\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\r\n",
    "        self.relu3=nn.ReLU()\r\n",
    "        #Shape= (batch_size,32,128,128)\r\n",
    "\r\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\r\n",
    "\r\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\r\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=64)\r\n",
    "        self.relu4 = nn.ReLU()\r\n",
    "        # Shape = (batch_size,64,64,64)\r\n",
    "\r\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\r\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=128)\r\n",
    "        self.relu5 = nn.ReLU()\r\n",
    "        # Shape = (batch_size,128,64,64)\r\n",
    "\r\n",
    "        \r\n",
    "        self.fc=nn.Linear(in_features=128*64*64 ,out_features=num_classes)\r\n",
    "        \r\n",
    "        \r\n",
    "        \r\n",
    "        #Feed forwad function\r\n",
    "        \r\n",
    "    def forward(self,input):\r\n",
    "        output=self.conv1(input)\r\n",
    "        output=self.bn1(output)\r\n",
    "        output=self.relu1(output)\r\n",
    "            \r\n",
    "        output=self.pool1(output)\r\n",
    "            \r\n",
    "        output=self.conv2(output)\r\n",
    "        output=self.relu2(output)\r\n",
    "            \r\n",
    "        output=self.conv3(output)\r\n",
    "        output=self.bn3(output)\r\n",
    "        output=self.relu3(output)\r\n",
    "        \r\n",
    "        output=self.pool2(output)\r\n",
    "\r\n",
    "        output=self.conv4(output)\r\n",
    "        output=self.bn4(output)\r\n",
    "        output=self.relu4(output)\r\n",
    "\r\n",
    "        output=self.conv5(output)\r\n",
    "        output=self.bn5(output)\r\n",
    "        output=self.relu5(output)\r\n",
    "\r\n",
    "            \r\n",
    "        #Above output will be in matrix form, with shape (256,128,64,64)\r\n",
    "        \r\n",
    "        output=output.view(-1,128*64*64)\r\n",
    "            \r\n",
    "            \r\n",
    "        output=self.fc(output)\r\n",
    "            \r\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "## Inception Net\r\n",
    "\r\n",
    "class GoogLeNet(nn.Module):\r\n",
    "    def __init__(self, aux_logits=True, num_classes=10):\r\n",
    "        super(GoogLeNet, self).__init__()\r\n",
    "        assert aux_logits == True or aux_logits == False\r\n",
    "        self.aux_logits = aux_logits\r\n",
    "\r\n",
    "        # Write in_channels, etc, all explicit in self.conv1, rest will write to\r\n",
    "        # make everything as compact as possible, kernel_size=3 instead of (3,3)\r\n",
    "        self.conv1 = conv_block(\r\n",
    "            in_channels=3,\r\n",
    "            out_channels=64,\r\n",
    "            kernel_size=(7, 7),\r\n",
    "            stride=(2, 2),\r\n",
    "            padding=(3, 3),\r\n",
    "        )\r\n",
    "\r\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
    "        self.conv2 = conv_block(64, 192, kernel_size=3, stride=1, padding=1)\r\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
    "\r\n",
    "        # In this order: in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\r\n",
    "        self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\r\n",
    "        self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\r\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=(3, 3), stride=2, padding=1)\r\n",
    "\r\n",
    "        self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\r\n",
    "        self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\r\n",
    "        self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\r\n",
    "        self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\r\n",
    "        self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\r\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
    "\r\n",
    "        self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\r\n",
    "        self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\r\n",
    "\r\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\r\n",
    "        self.dropout = nn.Dropout(p=0.4)\r\n",
    "        self.fc1 = nn.Linear(1024, num_classes)\r\n",
    "\r\n",
    "        if self.aux_logits:\r\n",
    "            self.aux1 = InceptionAux(512, num_classes)\r\n",
    "            self.aux2 = InceptionAux(528, num_classes)\r\n",
    "        else:\r\n",
    "            self.aux1 = self.aux2 = None\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.maxpool1(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        # x = self.conv3(x)\r\n",
    "        x = self.maxpool2(x)\r\n",
    "\r\n",
    "        x = self.inception3a(x)\r\n",
    "        x = self.inception3b(x)\r\n",
    "        x = self.maxpool3(x)\r\n",
    "\r\n",
    "        x = self.inception4a(x)\r\n",
    "\r\n",
    "        # Auxiliary Softmax classifier 1\r\n",
    "        if self.aux_logits and self.training:\r\n",
    "            aux1 = self.aux1(x)\r\n",
    "\r\n",
    "        x = self.inception4b(x)\r\n",
    "        x = self.inception4c(x)\r\n",
    "        x = self.inception4d(x)\r\n",
    "\r\n",
    "        # Auxiliary Softmax classifier 2\r\n",
    "        if self.aux_logits and self.training:\r\n",
    "            aux2 = self.aux2(x)\r\n",
    "\r\n",
    "        x = self.inception4e(x)\r\n",
    "        x = self.maxpool4(x)\r\n",
    "        x = self.inception5a(x)\r\n",
    "        x = self.inception5b(x)\r\n",
    "        x = self.avgpool(x)\r\n",
    "        x = x.reshape(x.shape[0], -1)\r\n",
    "        x = self.dropout(x)\r\n",
    "        x = self.fc1(x)\r\n",
    "\r\n",
    "        if self.aux_logits and self.training:\r\n",
    "            return aux1, aux2, x\r\n",
    "        else:\r\n",
    "            return x\r\n",
    "\r\n",
    "\r\n",
    "class Inception_block(nn.Module):\r\n",
    "    def __init__(\r\n",
    "        self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\r\n",
    "    ):\r\n",
    "        super(Inception_block, self).__init__()\r\n",
    "        self.branch1 = conv_block(in_channels, out_1x1, kernel_size=(1, 1))\r\n",
    "\r\n",
    "        self.branch2 = nn.Sequential(\r\n",
    "            conv_block(in_channels, red_3x3, kernel_size=(1, 1)),\r\n",
    "            conv_block(red_3x3, out_3x3, kernel_size=(3, 3), padding=(1, 1)),\r\n",
    "        )\r\n",
    "\r\n",
    "        self.branch3 = nn.Sequential(\r\n",
    "            conv_block(in_channels, red_5x5, kernel_size=(1, 1)),\r\n",
    "            conv_block(red_5x5, out_5x5, kernel_size=(5, 5), padding=(2, 2)),\r\n",
    "        )\r\n",
    "\r\n",
    "        self.branch4 = nn.Sequential(\r\n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\r\n",
    "            conv_block(in_channels, out_1x1pool, kernel_size=(1, 1)),\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return torch.cat(\r\n",
    "            [self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1\r\n",
    "        )\r\n",
    "\r\n",
    "\r\n",
    "class InceptionAux(nn.Module):\r\n",
    "    def __init__(self, in_channels, num_classes):\r\n",
    "        super(InceptionAux, self).__init__()\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.dropout = nn.Dropout(p=0.7)\r\n",
    "        self.pool = nn.AvgPool2d(kernel_size=5, stride=3)\r\n",
    "        self.conv = conv_block(in_channels, 128, kernel_size=1)\r\n",
    "        self.fc1 = nn.Linear(2048, 1024)\r\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.pool(x)\r\n",
    "        x = self.conv(x)\r\n",
    "        x = x.reshape(x.shape[0], -1)\r\n",
    "        x = self.relu(self.fc1(x))\r\n",
    "        x = self.dropout(x)\r\n",
    "        x = self.fc2(x)\r\n",
    "\r\n",
    "        return x\r\n",
    "\r\n",
    "\r\n",
    "class conv_block(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\r\n",
    "        super(conv_block, self).__init__()\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\r\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.relu(self.batchnorm(self.conv(x)))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "## Efficient Net\r\n",
    "\r\n",
    "from math import ceil\r\n",
    "\r\n",
    "base_model = [\r\n",
    "    # expand_ratio, channels, repeats, stride, kernel_size\r\n",
    "    [1, 16, 1, 1, 3],\r\n",
    "    [6, 24, 2, 2, 3],\r\n",
    "    [6, 40, 2, 2, 5],\r\n",
    "    [6, 80, 3, 2, 3],\r\n",
    "    [6, 112, 3, 1, 5],\r\n",
    "    [6, 192, 4, 2, 5],\r\n",
    "    [6, 320, 1, 1, 3],\r\n",
    "]\r\n",
    "\r\n",
    "phi_values = {\r\n",
    "    # tuple of: (phi_value, resolution, drop_rate)\r\n",
    "    \"b0\": (0, 224, 0.2),  # alpha, beta, gamma, depth = alpha ** phi\r\n",
    "    \"b1\": (0.5, 240, 0.2),\r\n",
    "    \"b2\": (1, 260, 0.3),\r\n",
    "    \"b3\": (2, 300, 0.3),\r\n",
    "    \"b4\": (3, 380, 0.4),\r\n",
    "    \"b5\": (4, 456, 0.4),\r\n",
    "    \"b6\": (5, 528, 0.5),\r\n",
    "    \"b7\": (6, 600, 0.5),\r\n",
    "}\r\n",
    "\r\n",
    "class CNNBlock(nn.Module):\r\n",
    "    def __init__(\r\n",
    "            self, in_channels, out_channels, kernel_size, stride, padding, groups=1\r\n",
    "    ):\r\n",
    "        super(CNNBlock, self).__init__()\r\n",
    "        self.cnn = nn.Conv2d(\r\n",
    "            in_channels,\r\n",
    "            out_channels,\r\n",
    "            kernel_size,\r\n",
    "            stride,\r\n",
    "            padding,\r\n",
    "            groups=groups,\r\n",
    "            bias=False,\r\n",
    "        )\r\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\r\n",
    "        self.silu = nn.SiLU() # SiLU <-> Swish\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.silu(self.bn(self.cnn(x)))\r\n",
    "\r\n",
    "class SqueezeExcitation(nn.Module):\r\n",
    "    def __init__(self, in_channels, reduced_dim):\r\n",
    "        super(SqueezeExcitation, self).__init__()\r\n",
    "        self.se = nn.Sequential(\r\n",
    "            nn.AdaptiveAvgPool2d(1), # C x H x W -> C x 1 x 1\r\n",
    "            nn.Conv2d(in_channels, reduced_dim, 1),\r\n",
    "            nn.SiLU(),\r\n",
    "            nn.Conv2d(reduced_dim, in_channels, 1),\r\n",
    "            nn.Sigmoid(),\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return x * self.se(x)\r\n",
    "\r\n",
    "class InvertedResidualBlock(nn.Module):\r\n",
    "    def __init__(\r\n",
    "            self,\r\n",
    "            in_channels,\r\n",
    "            out_channels,\r\n",
    "            kernel_size,\r\n",
    "            stride,\r\n",
    "            padding,\r\n",
    "            expand_ratio,\r\n",
    "            reduction=4, # squeeze excitation\r\n",
    "            survival_prob=0.8, # for stochastic depth\r\n",
    "    ):\r\n",
    "        super(InvertedResidualBlock, self).__init__()\r\n",
    "        self.survival_prob = 0.8\r\n",
    "        self.use_residual = in_channels == out_channels and stride == 1\r\n",
    "        hidden_dim = in_channels * expand_ratio\r\n",
    "        self.expand = in_channels != hidden_dim\r\n",
    "        reduced_dim = int(in_channels / reduction)\r\n",
    "\r\n",
    "        if self.expand:\r\n",
    "            self.expand_conv = CNNBlock(\r\n",
    "                in_channels, hidden_dim, kernel_size=3, stride=1, padding=1,\r\n",
    "            )\r\n",
    "\r\n",
    "        self.conv = nn.Sequential(\r\n",
    "            CNNBlock(\r\n",
    "                hidden_dim, hidden_dim, kernel_size, stride, padding, groups=hidden_dim,\r\n",
    "            ),\r\n",
    "            SqueezeExcitation(hidden_dim, reduced_dim),\r\n",
    "            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\r\n",
    "            nn.BatchNorm2d(out_channels),\r\n",
    "        )\r\n",
    "\r\n",
    "    def stochastic_depth(self, x):\r\n",
    "        if not self.training:\r\n",
    "            return x\r\n",
    "\r\n",
    "        binary_tensor = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob\r\n",
    "        return torch.div(x, self.survival_prob) * binary_tensor\r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        x = self.expand_conv(inputs) if self.expand else inputs\r\n",
    "\r\n",
    "        if self.use_residual:\r\n",
    "            return self.stochastic_depth(self.conv(x)) + inputs\r\n",
    "        else:\r\n",
    "            return self.conv(x)\r\n",
    "\r\n",
    "\r\n",
    "class EfficientNet(nn.Module):\r\n",
    "    def __init__(self, version, num_classes):\r\n",
    "        super(EfficientNet, self).__init__()\r\n",
    "        width_factor, depth_factor, dropout_rate = self.calculate_factors(version)\r\n",
    "        last_channels = ceil(1280 * width_factor)\r\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\r\n",
    "        self.features = self.create_features(width_factor, depth_factor, last_channels)\r\n",
    "        self.classifier = nn.Sequential(\r\n",
    "            nn.Dropout(dropout_rate),\r\n",
    "            nn.Linear(last_channels, num_classes),\r\n",
    "        )\r\n",
    "\r\n",
    "    def calculate_factors(self, version, alpha=1.2, beta=1.1):\r\n",
    "        phi, res, drop_rate = phi_values[version]\r\n",
    "        depth_factor = alpha ** phi\r\n",
    "        width_factor = beta ** phi\r\n",
    "        return width_factor, depth_factor, drop_rate\r\n",
    "\r\n",
    "    def create_features(self, width_factor, depth_factor, last_channels):\r\n",
    "        channels = int(32 * width_factor)\r\n",
    "        features = [CNNBlock(3, channels, 3, stride=2, padding=1)]\r\n",
    "        in_channels = channels\r\n",
    "\r\n",
    "        for expand_ratio, channels, repeats, stride, kernel_size in base_model:\r\n",
    "            out_channels = 4*ceil(int(channels*width_factor) / 4)\r\n",
    "            layers_repeats = ceil(repeats * depth_factor)\r\n",
    "\r\n",
    "            for layer in range(layers_repeats):\r\n",
    "                features.append(\r\n",
    "                    InvertedResidualBlock(\r\n",
    "                        in_channels,\r\n",
    "                        out_channels,\r\n",
    "                        expand_ratio=expand_ratio,\r\n",
    "                        stride = stride if layer == 0 else 1,\r\n",
    "                        kernel_size=kernel_size,\r\n",
    "                        padding=kernel_size//2, # if k=1:pad=0, k=3:pad=1, k=5:pad=2\r\n",
    "                    )\r\n",
    "                )\r\n",
    "                in_channels = out_channels\r\n",
    "\r\n",
    "        features.append(\r\n",
    "            CNNBlock(in_channels, last_channels, kernel_size=1, stride=1, padding=0)\r\n",
    "        )\r\n",
    "\r\n",
    "        return nn.Sequential(*features)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.pool(self.features(x))\r\n",
    "        return self.classifier(x.view(x.shape[0], -1))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "## For the submission with best accuracy GoogLeNet with aux_logits as False was used\r\n",
    "\r\n",
    "model = GoogLeNet(aux_logits=False, num_classes=len(classes)).to(device)  #* Without logits works best\r\n",
    "\r\n",
    "# model = GoogLeNet(aux_logits=True, num_classes=len(classes)).to(device)  #* Without logits works best\r\n",
    "\r\n",
    "# model = EfficientNet(version= \"b0\" ,num_classes=len(classes)).to(device)   #* Useless Model\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observations\r\n",
    "\r\n",
    "For GoogLeNet \r\n",
    "- batch size of 32 and 20 epochs \r\n",
    "  - the training accuracy is about 0.98. It gives tennis courts and basket ball courts as Runway. 117 --> Crosswalk, 199--> Runway.\r\n",
    "\r\n",
    "- Batch size 40 out of memory\r\n",
    "\r\n",
    "- Batch size 36, epochs 20 \r\n",
    "  - training accuracy 0.99. Again gives tennis courts and basket ball courts as Runway. 117 --> basketball_court, 199--> Runway.\r\n",
    "  - Better than batch size 32.\r\n",
    "\r\n",
    "- Batch size 36, epochs 30\r\n",
    "  - training accuracy 1. Gives tennis courts and basket ball courts correct. 117 --> Railway, 120--> railway 199--> Runway.\r\n",
    "  - Maybe the model is overfitting.\r\n",
    "\r\n",
    "- With more Data Augmentation\r\n",
    "  - Batch size 32, epochs 30\r\n",
    "   - Seems training did not complete\r\n",
    "   - Wrong output for images with shadows.\r\n",
    "\r\n",
    "  - added image crop, epochs 50\r\n",
    "   - - Shadows issue seems to be resoloved.\r\n",
    "   - - But Oilwells not classified properly.\r\n",
    "   - - 117--> Tennis_court, 120 --> Tennis_court, 199 --> Basketball_court. # All are correct.\r\n",
    "   - - Seems to me that random crop is not correct.\r\n",
    "  \r\n",
    "  - Removed image crop, epochs 50\r\n",
    "   - - Oilwells not classified properly again.\r\n",
    "   - - Seems crop is not the issue\r\n",
    "   - - The issue lies with higher epochs. \r\n",
    "   - - 117--> Basketball_court, 120 --> Basketball_court, 199 --> Crosswalk. \r\n",
    "\r\n",
    "  - Epochs 40\r\n",
    "  - - Didn't get so good results\r\n",
    "  - - 117--> Basketball_court, 120 --> Tennis_court, 199 --> Crosswalk. # Cross walk is wrong.\r\n",
    "\r\n",
    "  - CenterCrop instead of RandomCrop\r\n",
    "  - - Not so good results\r\n",
    "  - - Oilwells issue persists.\r\n",
    "  - - 117--> Basketball_court, 120 --> Tennis_court, 199 --> Basketball_court. # All correct\r\n",
    "  - - Seems training did not complete\r\n",
    "\r\n",
    "  Observation: Increasing epochs is making oilwell detection more difficult.\r\n",
    "\r\n",
    "For GoogleNet with Aux Logits True\r\n",
    "- batch size of 36 and 30 epochs\r\n",
    "  - Pretty bad model. Gives bridge as Basketball court. 117--> Basket ball court ,120--> Railway ,199--> Runway\r\n",
    "\r\n",
    "- batch size of 32 and 20 epochs\r\n",
    "  - Better than batch size 36 and 30 epochs. Good classification for basketball court and tennis court. 117 -->oilwell, 120 --> Railway, 199 --> Basketball court.\r\n",
    "\r\n",
    "For EffecientNet \r\n",
    "- batch size of 32 and 20 epochs\r\n",
    "  - out of memory\r\n",
    "\r\n",
    "- batch size of 16 and 20 epochs\r\n",
    "  - Didn't complete training.\r\n",
    "\r\n",
    "- batch size of 16 and 30 epochs\r\n",
    "  - Pretty bad model. Training accuracy is 1. Oil well not learnt at all. Lots of overpass and Crosswalk.\r\n",
    "   Gives bridge as Basketball court. 117--> Overpass ,120--> Overpass ,199--> Crosswalk"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optmizer and loss function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "\r\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\r\n",
    "loss_function=nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#calculating the size of training and testing images\r\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\r\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(train_count,test_count)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "500 100\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model training and saving best model \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "best_accuracy=0.0\r\n",
    "\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    \r\n",
    "    #Evaluation and training on training dataset\r\n",
    "    model.train()\r\n",
    "    train_accuracy=0.0\r\n",
    "    train_loss=0.0\r\n",
    "    \r\n",
    "    for i, (images,labels) in enumerate(train_loader):\r\n",
    "        if torch.cuda.is_available():\r\n",
    "            images=Variable(images.cuda())\r\n",
    "            labels=Variable(labels.cuda())\r\n",
    "            \r\n",
    "        optimizer.zero_grad()\r\n",
    "        \r\n",
    "        outputs=model(images)\r\n",
    "        loss=loss_function(outputs,labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        \r\n",
    "        train_loss+= loss.cpu().data*images.size(0)\r\n",
    "        _,prediction=torch.max(outputs.data,1)\r\n",
    "        \r\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\r\n",
    "        \r\n",
    "    train_accuracy=train_accuracy/train_count\r\n",
    "    train_loss=train_loss/train_count\r\n",
    "    \r\n",
    "    \r\n",
    "    # Evaluation on testing dataset\r\n",
    "    model.eval()\r\n",
    "    \r\n",
    "    test_accuracy=0.0\r\n",
    "    for i, (images,labels) in enumerate(test_loader):\r\n",
    "        if torch.cuda.is_available():\r\n",
    "            images=Variable(images.cuda())\r\n",
    "            labels=Variable(labels.cuda())\r\n",
    "            \r\n",
    "        outputs=model(images)\r\n",
    "        _,prediction=torch.max(outputs.data,1)\r\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\r\n",
    "    \r\n",
    "    test_accuracy=test_accuracy/test_count\r\n",
    "    \r\n",
    "    \r\n",
    "    print('Epoch: '+str(epoch+1)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\r\n",
    "    \r\n",
    "    #Save the best model\r\n",
    "    if test_accuracy>=best_accuracy:\r\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\r\n",
    "        best_accuracy=test_accuracy\r\n",
    "    \r\n",
    "       \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Vinit\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1 Train Loss: tensor(1.2571) Train Accuracy: 0.556 Test Accuracy: 0.1\n",
      "Epoch: 2 Train Loss: tensor(0.5865) Train Accuracy: 0.796 Test Accuracy: 0.4\n",
      "Epoch: 3 Train Loss: tensor(0.5470) Train Accuracy: 0.8 Test Accuracy: 0.34\n",
      "Epoch: 4 Train Loss: tensor(0.5383) Train Accuracy: 0.83 Test Accuracy: 0.81\n",
      "Epoch: 5 Train Loss: tensor(0.4466) Train Accuracy: 0.866 Test Accuracy: 0.66\n",
      "Epoch: 6 Train Loss: tensor(0.3822) Train Accuracy: 0.888 Test Accuracy: 0.81\n",
      "Epoch: 7 Train Loss: tensor(0.3914) Train Accuracy: 0.858 Test Accuracy: 0.68\n",
      "Epoch: 8 Train Loss: tensor(0.5393) Train Accuracy: 0.848 Test Accuracy: 0.88\n",
      "Epoch: 9 Train Loss: tensor(0.3064) Train Accuracy: 0.91 Test Accuracy: 0.9\n",
      "Epoch: 10 Train Loss: tensor(0.2936) Train Accuracy: 0.904 Test Accuracy: 0.84\n",
      "Epoch: 11 Train Loss: tensor(0.2681) Train Accuracy: 0.918 Test Accuracy: 0.76\n",
      "Epoch: 12 Train Loss: tensor(0.2960) Train Accuracy: 0.902 Test Accuracy: 0.94\n",
      "Epoch: 13 Train Loss: tensor(0.5082) Train Accuracy: 0.864 Test Accuracy: 0.81\n",
      "Epoch: 14 Train Loss: tensor(0.2761) Train Accuracy: 0.918 Test Accuracy: 0.96\n",
      "Epoch: 15 Train Loss: tensor(0.2311) Train Accuracy: 0.926 Test Accuracy: 0.96\n",
      "Epoch: 16 Train Loss: tensor(0.1825) Train Accuracy: 0.946 Test Accuracy: 0.89\n",
      "Epoch: 17 Train Loss: tensor(0.2835) Train Accuracy: 0.908 Test Accuracy: 0.92\n",
      "Epoch: 18 Train Loss: tensor(0.2113) Train Accuracy: 0.942 Test Accuracy: 0.9\n",
      "Epoch: 19 Train Loss: tensor(0.1630) Train Accuracy: 0.946 Test Accuracy: 0.89\n",
      "Epoch: 20 Train Loss: tensor(0.1723) Train Accuracy: 0.948 Test Accuracy: 0.96\n",
      "Epoch: 21 Train Loss: tensor(0.1013) Train Accuracy: 0.974 Test Accuracy: 0.85\n",
      "Epoch: 22 Train Loss: tensor(0.1694) Train Accuracy: 0.94 Test Accuracy: 0.77\n",
      "Epoch: 23 Train Loss: tensor(0.2594) Train Accuracy: 0.912 Test Accuracy: 0.8\n",
      "Epoch: 24 Train Loss: tensor(0.2763) Train Accuracy: 0.906 Test Accuracy: 0.85\n",
      "Epoch: 25 Train Loss: tensor(0.2209) Train Accuracy: 0.932 Test Accuracy: 0.83\n",
      "Epoch: 26 Train Loss: tensor(0.2236) Train Accuracy: 0.918 Test Accuracy: 0.92\n",
      "Epoch: 27 Train Loss: tensor(0.2087) Train Accuracy: 0.934 Test Accuracy: 0.82\n",
      "Epoch: 28 Train Loss: tensor(0.1684) Train Accuracy: 0.936 Test Accuracy: 0.97\n",
      "Epoch: 29 Train Loss: tensor(0.1472) Train Accuracy: 0.952 Test Accuracy: 1.0\n",
      "Epoch: 30 Train Loss: tensor(0.1604) Train Accuracy: 0.946 Test Accuracy: 0.68\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "checkpoint = torch.load('best_checkpoint.model')\r\n",
    "model.load_state_dict(checkpoint)\r\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): conv_block(\n",
       "    (relu): ReLU()\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv2): conv_block(\n",
       "    (relu): ReLU()\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception3a): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception4a): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception5a): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception_block(\n",
       "    (branch1): conv_block(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchnorm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "#Transforms\r\n",
    "transformer=transforms.Compose([\r\n",
    "    transforms.Resize((size,size)),\r\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\r\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\r\n",
    "                        [0.5,0.5,0.5])\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "## Making predictions\r\n",
    "from PIL import Image\r\n",
    "from io import open\r\n",
    "\r\n",
    "\r\n",
    "def prediction(path, transform):\r\n",
    "    image=Image.open(path)\r\n",
    "    image_tensor=transformer(image).float()\r\n",
    "    image_tensor=image_tensor.unsqueeze_(0)\r\n",
    "    image_tensor=image_tensor.to(device)\r\n",
    "    output=model(image_tensor)\r\n",
    "    _,prediction=torch.max(output.data,1)\r\n",
    "    return classes[prediction[0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "test_path = \"Dataset\\\\test\"\r\n",
    "image_path=glob.glob(test_path+'/*.jpg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "predictions={}\r\n",
    "for i,path in enumerate(image_path):\r\n",
    "    predictions[path[len(test_path)+1:]]=prediction(path,transformer)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "predictions"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'101.jpg': 'oil_well',\n",
       " '102.jpg': 'tennis_court',\n",
       " '103.jpg': 'crosswalk',\n",
       " '104.jpg': 'oil_well',\n",
       " '105.jpg': 'bridge',\n",
       " '106.jpg': 'crosswalk',\n",
       " '107.jpg': 'tennis_court',\n",
       " '108.jpg': 'golf_course',\n",
       " '109.jpg': 'bridge',\n",
       " '110.jpg': 'bridge',\n",
       " '111.jpg': 'bridge',\n",
       " '112.jpg': 'tennis_court',\n",
       " '113.jpg': 'oil_well',\n",
       " '114.jpg': 'overpass',\n",
       " '115.jpg': 'runway',\n",
       " '116.jpg': 'golf_course',\n",
       " '117.jpg': 'basketball_court',\n",
       " '118.jpg': 'oil_well',\n",
       " '119.jpg': 'runway',\n",
       " '120.jpg': 'tennis_court',\n",
       " '121.jpg': 'oil_well',\n",
       " '122.jpg': 'bridge',\n",
       " '123.jpg': 'overpass',\n",
       " '124.jpg': 'golf_course',\n",
       " '125.jpg': 'crosswalk',\n",
       " '126.jpg': 'overpass',\n",
       " '127.jpg': 'basketball_court',\n",
       " '128.jpg': 'basketball_court',\n",
       " '129.jpg': 'oil_well',\n",
       " '130.jpg': 'crosswalk',\n",
       " '131.jpg': 'golf_course',\n",
       " '132.jpg': 'basketball_court',\n",
       " '133.jpg': 'crosswalk',\n",
       " '134.jpg': 'runway',\n",
       " '135.jpg': 'bridge',\n",
       " '136.jpg': 'golf_course',\n",
       " '137.jpg': 'bridge',\n",
       " '138.jpg': 'bridge',\n",
       " '139.jpg': 'overpass',\n",
       " '140.jpg': 'golf_course',\n",
       " '141.jpg': 'tennis_court',\n",
       " '142.jpg': 'tennis_court',\n",
       " '143.jpg': 'basketball_court',\n",
       " '144.jpg': 'golf_course',\n",
       " '145.jpg': 'basketball_court',\n",
       " '146.jpg': 'golf_course',\n",
       " '147.jpg': 'tennis_court',\n",
       " '148.jpg': 'oil_well',\n",
       " '149.jpg': 'tennis_court',\n",
       " '150.jpg': 'golf_course',\n",
       " '151.jpg': 'runway',\n",
       " '152.jpg': 'tennis_court',\n",
       " '153.jpg': 'tennis_court',\n",
       " '154.jpg': 'overpass',\n",
       " '155.jpg': 'basketball_court',\n",
       " '156.jpg': 'golf_course',\n",
       " '157.jpg': 'tennis_court',\n",
       " '158.jpg': 'crosswalk',\n",
       " '159.jpg': 'basketball_court',\n",
       " '160.jpg': 'bridge',\n",
       " '161.jpg': 'tennis_court',\n",
       " '162.jpg': 'overpass',\n",
       " '163.jpg': 'golf_course',\n",
       " '164.jpg': 'bridge',\n",
       " '165.jpg': 'bridge',\n",
       " '166.jpg': 'golf_course',\n",
       " '167.jpg': 'tennis_court',\n",
       " '168.jpg': 'golf_course',\n",
       " '169.jpg': 'golf_course',\n",
       " '170.jpg': 'tennis_court',\n",
       " '171.jpg': 'oil_well',\n",
       " '172.jpg': 'overpass',\n",
       " '173.jpg': 'golf_course',\n",
       " '174.jpg': 'bridge',\n",
       " '175.jpg': 'runway',\n",
       " '176.jpg': 'crosswalk',\n",
       " '177.jpg': 'overpass',\n",
       " '178.jpg': 'basketball_court',\n",
       " '179.jpg': 'crosswalk',\n",
       " '180.jpg': 'golf_course',\n",
       " '181.jpg': 'bridge',\n",
       " '182.jpg': 'golf_course',\n",
       " '183.jpg': 'bridge',\n",
       " '184.jpg': 'tennis_court',\n",
       " '185.jpg': 'overpass',\n",
       " '186.jpg': 'tennis_court',\n",
       " '187.jpg': 'runway',\n",
       " '188.jpg': 'crosswalk',\n",
       " '189.jpg': 'oil_well',\n",
       " '190.jpg': 'crosswalk',\n",
       " '191.jpg': 'overpass',\n",
       " '192.jpg': 'golf_course',\n",
       " '193.jpg': 'overpass',\n",
       " '194.jpg': 'golf_course',\n",
       " '195.jpg': 'bridge',\n",
       " '196.jpg': 'basketball_court',\n",
       " '197.jpg': 'oil_well',\n",
       " '198.jpg': 'golf_course',\n",
       " '199.jpg': 'crosswalk',\n",
       " '200.jpg': 'basketball_court'}"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "label_dict = {\r\n",
    "    \"basketball_court\": 1, \r\n",
    "    \"bridge\":2, \r\n",
    "    \"crosswalk\":3, \r\n",
    "    \"golf_course\":4, \r\n",
    "    \"oil_well\":5, \r\n",
    "    \"overpass\":6, \r\n",
    "    \"railway\":7, \r\n",
    "    \"runway\":8, \r\n",
    "    \"swimming_pool\":9, \r\n",
    "    \"tennis_court\":10\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "## Convert the predictions to labels from label_dict\r\n",
    "predictions_labels={}\r\n",
    "for key,value in predictions.items():\r\n",
    "    predictions_labels[key]=label_dict[value]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "predictions_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'101.jpg': 5,\n",
       " '102.jpg': 10,\n",
       " '103.jpg': 3,\n",
       " '104.jpg': 5,\n",
       " '105.jpg': 2,\n",
       " '106.jpg': 3,\n",
       " '107.jpg': 10,\n",
       " '108.jpg': 4,\n",
       " '109.jpg': 2,\n",
       " '110.jpg': 2,\n",
       " '111.jpg': 2,\n",
       " '112.jpg': 10,\n",
       " '113.jpg': 5,\n",
       " '114.jpg': 6,\n",
       " '115.jpg': 8,\n",
       " '116.jpg': 4,\n",
       " '117.jpg': 1,\n",
       " '118.jpg': 5,\n",
       " '119.jpg': 8,\n",
       " '120.jpg': 10,\n",
       " '121.jpg': 5,\n",
       " '122.jpg': 2,\n",
       " '123.jpg': 6,\n",
       " '124.jpg': 4,\n",
       " '125.jpg': 3,\n",
       " '126.jpg': 6,\n",
       " '127.jpg': 1,\n",
       " '128.jpg': 1,\n",
       " '129.jpg': 5,\n",
       " '130.jpg': 3,\n",
       " '131.jpg': 4,\n",
       " '132.jpg': 1,\n",
       " '133.jpg': 3,\n",
       " '134.jpg': 8,\n",
       " '135.jpg': 2,\n",
       " '136.jpg': 4,\n",
       " '137.jpg': 2,\n",
       " '138.jpg': 2,\n",
       " '139.jpg': 6,\n",
       " '140.jpg': 4,\n",
       " '141.jpg': 10,\n",
       " '142.jpg': 10,\n",
       " '143.jpg': 1,\n",
       " '144.jpg': 4,\n",
       " '145.jpg': 1,\n",
       " '146.jpg': 4,\n",
       " '147.jpg': 10,\n",
       " '148.jpg': 5,\n",
       " '149.jpg': 10,\n",
       " '150.jpg': 4,\n",
       " '151.jpg': 8,\n",
       " '152.jpg': 10,\n",
       " '153.jpg': 10,\n",
       " '154.jpg': 6,\n",
       " '155.jpg': 1,\n",
       " '156.jpg': 4,\n",
       " '157.jpg': 10,\n",
       " '158.jpg': 3,\n",
       " '159.jpg': 1,\n",
       " '160.jpg': 2,\n",
       " '161.jpg': 10,\n",
       " '162.jpg': 6,\n",
       " '163.jpg': 4,\n",
       " '164.jpg': 2,\n",
       " '165.jpg': 2,\n",
       " '166.jpg': 4,\n",
       " '167.jpg': 10,\n",
       " '168.jpg': 4,\n",
       " '169.jpg': 4,\n",
       " '170.jpg': 10,\n",
       " '171.jpg': 5,\n",
       " '172.jpg': 6,\n",
       " '173.jpg': 4,\n",
       " '174.jpg': 2,\n",
       " '175.jpg': 8,\n",
       " '176.jpg': 3,\n",
       " '177.jpg': 6,\n",
       " '178.jpg': 1,\n",
       " '179.jpg': 3,\n",
       " '180.jpg': 4,\n",
       " '181.jpg': 2,\n",
       " '182.jpg': 4,\n",
       " '183.jpg': 2,\n",
       " '184.jpg': 10,\n",
       " '185.jpg': 6,\n",
       " '186.jpg': 10,\n",
       " '187.jpg': 8,\n",
       " '188.jpg': 3,\n",
       " '189.jpg': 5,\n",
       " '190.jpg': 3,\n",
       " '191.jpg': 6,\n",
       " '192.jpg': 4,\n",
       " '193.jpg': 6,\n",
       " '194.jpg': 4,\n",
       " '195.jpg': 2,\n",
       " '196.jpg': 1,\n",
       " '197.jpg': 5,\n",
       " '198.jpg': 4,\n",
       " '199.jpg': 3,\n",
       " '200.jpg': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting the predictions to CSV format"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Convert predictions to dataframe\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# Make a dataframe with the predictions with column names as ImageID and LabelID\r\n",
    "predictions_df = pd.DataFrame.from_dict(predictions_labels, orient='index')\r\n",
    "\r\n",
    "# Removing the .jpg from the file names\r\n",
    "predictions_df.index=predictions_df.index.str.replace('.jpg','')\r\n",
    "\r\n",
    "# Naming the columns as ImageID and Label\r\n",
    "predictions_df.reset_index(level=0, inplace=True)\r\n",
    "predictions_df.columns = ['ImageID', 'LabelID']\r\n",
    "\r\n",
    "# Removing the index from the dataframe\r\n",
    "predictions_df.reset_index(drop= True, inplace=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Vinit\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "predictions_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>LabelID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>197</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>199</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageID  LabelID\n",
       "0      101        5\n",
       "1      102       10\n",
       "2      103        3\n",
       "3      104        5\n",
       "4      105        2\n",
       "..     ...      ...\n",
       "95     196        1\n",
       "96     197        5\n",
       "97     198        4\n",
       "98     199        3\n",
       "99     200        1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "## Saving the predictions to csv\r\n",
    "predictions_df.to_csv('18D070067.csv',index=False)   #18D070067.csv is the name of the csv file and the index have been dropped"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hence, the implementation of the model is complete and the predictions are converted to CSV format."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('gpu-pytorch': conda)"
  },
  "interpreter": {
   "hash": "3d1484f6a5966aacf1d005944f88794f1e4469136ed9878e517c1d6594061a94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}