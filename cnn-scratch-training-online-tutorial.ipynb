{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Load libraries\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "import glob\r\n",
    "import torch.nn as nn\r\n",
    "from torchvision.transforms import transforms\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.optim import Adam\r\n",
    "from torch.autograd import Variable\r\n",
    "import torchvision\r\n",
    "import pathlib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#checking for device\r\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "## Hyperparameters\r\n",
    "batch_size_ = 8\r\n",
    "num_epochs = 10\r\n",
    "size = 256"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Transforms\r\n",
    "transformer=transforms.Compose([\r\n",
    "    transforms.Resize((size,size)),\r\n",
    "    transforms.RandomHorizontalFlip(),\r\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\r\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\r\n",
    "                        [0.5,0.5,0.5])\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Dataloader\r\n",
    "\r\n",
    "#Path for training and testing directory\r\n",
    "train_path='Dataset\\\\train'\r\n",
    "test_path='Dataset\\\\val'\r\n",
    "\r\n",
    "train_loader=DataLoader(\r\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\r\n",
    "    batch_size=batch_size_, shuffle=True\r\n",
    ")\r\n",
    "test_loader=DataLoader(\r\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\r\n",
    "    batch_size=batch_size_, shuffle=True\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#categories\r\n",
    "root=pathlib.Path(train_path)\r\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['basketball_court', 'bridge', 'crosswalk', 'golf_course', 'oil_well', 'overpass', 'railway', 'runway', 'swimming_pool', 'tennis_court']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#CNN Network\r\n",
    "\r\n",
    "\r\n",
    "class ConvNet(nn.Module):\r\n",
    "    def __init__(self,num_classes=6):\r\n",
    "        super(ConvNet,self).__init__()\r\n",
    "        \r\n",
    "        #Output size after convolution filter\r\n",
    "        #((w-f+2P)/s) +1\r\n",
    "        \r\n",
    "        #Input shape= (batch_size,3,256,256)\r\n",
    "        \r\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=64,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (batch_size,64,256,256)\r\n",
    "        self.bn1=nn.BatchNorm2d(num_features=64)\r\n",
    "        #Shape= (batch_size,64,256,256)\r\n",
    "        self.relu1=nn.ReLU()\r\n",
    "        #Shape= (batch_size,64,256,256) \r\n",
    "        \r\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2)\r\n",
    "        #Reduce the image size be factor 2\r\n",
    "        #Shape= (batch_size,64,128,128)\r\n",
    "        \r\n",
    "        self.conv2=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (batch_size,128,128,128)\r\n",
    "        self.bn2=nn.BatchNorm2d(num_features=128)\r\n",
    "        #Shape= (batch_size,128,128,128)\r\n",
    "        self.relu2=nn.ReLU()\r\n",
    "        #Shape= (batch_size,128,128,128)\r\n",
    "        \r\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=2)\r\n",
    "        #Reduce the image size be factor 2\r\n",
    "        #Shape= (batch_size,128,64,64)\r\n",
    "\r\n",
    "        self.conv3=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (batch_size,256,64,64)\r\n",
    "        self.bn3=nn.BatchNorm2d(num_features=256)\r\n",
    "        #Shape= (batch_size,256,64,64)\r\n",
    "        self.relu3=nn.ReLU()\r\n",
    "        #Shape= (batch_size,256,64,64)\r\n",
    "\r\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=2)\r\n",
    "        #Reduce the image size be factor 2\r\n",
    "        #Shape= (batch_size,256,32,32)\r\n",
    "        \r\n",
    "        self.fc1=nn.Linear(in_features=256*32*32,out_features=2048)\r\n",
    "        #Shape= (batch_size,2048)\r\n",
    "        self.relu11=nn.ReLU()\r\n",
    "        #Shape= (batch_size,2048)\r\n",
    "        self.dropout1=nn.Dropout(p=0.5)\r\n",
    "        #Shape= (batch_size,2048)\r\n",
    "\r\n",
    "        self.fc2=nn.Linear(in_features=2048,out_features=2048)\r\n",
    "        #Shape= (batch_size,2048)\r\n",
    "        self.relu12=nn.ReLU()\r\n",
    "        #Shape= (batch_size,2048)\r\n",
    "        self.dropout2=nn.Dropout(p=0.5)\r\n",
    "        #Shape= (batch_size,2048)\r\n",
    "        \r\n",
    "        self.fc3=nn.Linear(in_features=2048,out_features=num_classes)\r\n",
    "        #Shape= (batch_size,num_classes)\r\n",
    "        \r\n",
    "        \r\n",
    "        #Feed forwad function\r\n",
    "        \r\n",
    "    def forward(self,input):\r\n",
    "        output=self.conv1(input)\r\n",
    "        output=self.bn1(output)\r\n",
    "        output=self.relu1(output)\r\n",
    "        output=self.pool1(output)\r\n",
    "\r\n",
    "        output=self.conv2(output)\r\n",
    "        output=self.bn2(output)\r\n",
    "        output=self.relu2(output)\r\n",
    "        output=self.pool2(output)\r\n",
    "\r\n",
    "        output=self.conv3(output)\r\n",
    "        output=self.bn3(output)\r\n",
    "        output=self.relu3(output)\r\n",
    "        output=self.pool3(output)\r\n",
    "\r\n",
    "        output=output.view(output.size(0),-1)\r\n",
    "        output=self.fc1(output)\r\n",
    "        output=self.relu11(output)\r\n",
    "        output=self.dropout1(output)\r\n",
    "\r\n",
    "        output=self.fc2(output)\r\n",
    "        output=self.relu12(output)\r\n",
    "        output=self.dropout2(output)\r\n",
    "\r\n",
    "        output=self.fc3(output)    \r\n",
    "        return output\r\n",
    "            \r\n",
    "        \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "## VGG Network\r\n",
    "\r\n",
    "VGG_types = {\r\n",
    "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\r\n",
    "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\r\n",
    "    \"VGG16\": [64,64,\"M\",128,128,\"M\",256,256,256,\"M\",512,512,512,\"M\",512,512,512,\"M\"],\r\n",
    "    \"VGG19\": [64,64,\"M\",128,128,\"M\",256,256,256,256,\"M\",512,512,512,512,\"M\",512,512,512,512,\"M\"],\r\n",
    "}\r\n",
    "\r\n",
    "\r\n",
    "class VGG_net(nn.Module):\r\n",
    "    def __init__(self, in_channels, num_classes, type=\"VGG16\"):\r\n",
    "        super(VGG_net, self).__init__()\r\n",
    "        self.in_channels = in_channels\r\n",
    "        self.conv_layers = self.create_conv_layers(VGG_types[type])\r\n",
    "\r\n",
    "        self.fcs = nn.Sequential(\r\n",
    "            nn.Linear(512 * 7 * 7, 4096),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.5),\r\n",
    "            nn.Linear(4096, 4096),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.5),\r\n",
    "            nn.Linear(4096, num_classes),\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv_layers(x)\r\n",
    "        x = x.reshape(x.shape[0], -1)\r\n",
    "        x = self.fcs(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "    def create_conv_layers(self, architecture):\r\n",
    "        layers = []\r\n",
    "        in_channels = self.in_channels\r\n",
    "\r\n",
    "        for x in architecture:\r\n",
    "            if type(x) == int:\r\n",
    "                out_channels = x\r\n",
    "\r\n",
    "                layers += [\r\n",
    "                    nn.Conv2d(\r\n",
    "                        in_channels=in_channels,\r\n",
    "                        out_channels=out_channels,\r\n",
    "                        kernel_size=(3, 3),\r\n",
    "                        stride=(1, 1),\r\n",
    "                        padding=(1, 1),\r\n",
    "                    ),\r\n",
    "                    nn.BatchNorm2d(x),\r\n",
    "                    nn.ReLU(),\r\n",
    "                ]\r\n",
    "                in_channels = x\r\n",
    "            elif x == \"M\":\r\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\r\n",
    "\r\n",
    "        return nn.Sequential(*layers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "## My implementation of VGG16\r\n",
    "\r\n",
    "class MyVGG16(nn.Module):\r\n",
    "    def __init__(self,num_classes):\r\n",
    "        super(MyVGG16,self).__init__()\r\n",
    "        \r\n",
    "        #Output size after convolution filter\r\n",
    "        #((w-f+2P)/s) +1\r\n",
    "        \r\n",
    "        #Input shape= (4,3,224,224)\r\n",
    "        \r\n",
    "        self.conv11=nn.Conv2d(in_channels=3,out_channels=64,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,64,224,224)\r\n",
    "        self.bn11=nn.BatchNorm2d(num_features=64)\r\n",
    "        #Shape= (4,64,224,224)\r\n",
    "        self.relu11=nn.ReLU()\r\n",
    "        #Shape= (4,64,224,224)\r\n",
    "\r\n",
    "        self.conv12=nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,64,224,224)\r\n",
    "        self.bn12=nn.BatchNorm2d(num_features=64)\r\n",
    "        #Shape= (4,64,224,224)\r\n",
    "        self.relu12=nn.ReLU()\r\n",
    "        #Shape= (4,64,224,224)\r\n",
    "        \r\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
    "        #Reduce the image size be factor 2\r\n",
    "        #Shape= (4,64,112,112)\r\n",
    "        \r\n",
    "#############################################################################################\r\n",
    "        self.conv21=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,128,112,112)\r\n",
    "        self.bn21=nn.BatchNorm2d(num_features=128)\r\n",
    "        #Shape= (4,128,112,112)\r\n",
    "        self.relu21=nn.ReLU()\r\n",
    "        #Shape= (4,128,112,112)\r\n",
    "        \r\n",
    "        self.conv22=nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,128,112,112)\r\n",
    "        self.bn22=nn.BatchNorm2d(num_features=128)\r\n",
    "        #Shape= (4,128,112,112)\r\n",
    "        self.relu22=nn.ReLU()\r\n",
    "        #Shape= (4,128,112,112)\r\n",
    "\r\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
    "        #Reduce the image size be factor 2\r\n",
    "        #Shape= (4,128,56,56)\r\n",
    "\r\n",
    "##############################################################################################\r\n",
    "\r\n",
    "        self.conv31=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1) \r\n",
    "        #Shape= (4,256,56,56)\r\n",
    "        self.bn31=nn.BatchNorm2d(num_features=256)   \r\n",
    "        #Shape= (4,256,56,56)\r\n",
    "        self.relu31=nn.ReLU()\r\n",
    "        #Shape= (4,256,56,56)\r\n",
    "\r\n",
    "        self.conv32=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,256,56,56)\r\n",
    "        self.bn32=nn.BatchNorm2d(num_features=256)\r\n",
    "        #Shape= (4,256,56,56)\r\n",
    "        self.relu32=nn.ReLU()\r\n",
    "        #Shape= (4,256,56,56)\r\n",
    "\r\n",
    "        self.conv33=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,256,56,56)\r\n",
    "        self.bn33=nn.BatchNorm2d(num_features=256)\r\n",
    "        #Shape= (4,256,56,56)\r\n",
    "        self.relu33=nn.ReLU()\r\n",
    "        #Shape= (4,256,56,56)\r\n",
    "\r\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
    "        #Reduce the image size be factor 2\r\n",
    "        #Shape= (4,256,28,28)\r\n",
    "\r\n",
    "###########################################################################################\r\n",
    "        self.conv41=nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,512,28,28)\r\n",
    "        self.bn41=nn.BatchNorm2d(num_features=512)\r\n",
    "        #Shape= (4,512,28,28)\r\n",
    "        self.relu41=nn.ReLU()\r\n",
    "        #Shape= (4,512,28,28)\r\n",
    "\r\n",
    "        self.conv42=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,512,28,28)\r\n",
    "        self.bn42=nn.BatchNorm2d(num_features=512)\r\n",
    "        #Shape= (4,512,28,28)\r\n",
    "        self.relu42=nn.ReLU()\r\n",
    "        #Shape= (4,512,28,28)\r\n",
    "\r\n",
    "        self.conv43=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,512,28,28)\r\n",
    "        self.bn43=nn.BatchNorm2d(num_features=512)\r\n",
    "        #Shape= (4,512,28,28)\r\n",
    "        self.relu43=nn.ReLU()\r\n",
    "        #Shape= (4,512,28,28)\r\n",
    "\r\n",
    "        self.pool4=nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
    "        #Reduce the image size be factor 2\r\n",
    "        #Shape= (4,512,14,14)\r\n",
    "        \r\n",
    "#############################################################################################\r\n",
    "\r\n",
    "        self.conv51=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,512,14,14)\r\n",
    "        self.bn51=nn.BatchNorm2d(num_features=512)\r\n",
    "        #Shape= (4,512,14,14)\r\n",
    "        self.relu51=nn.ReLU()\r\n",
    "        #Shape= (4,512,14,14)\r\n",
    "        \r\n",
    "        self.conv52=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,512,14,14)\r\n",
    "        self.bn52=nn.BatchNorm2d(num_features=512)\r\n",
    "        #Shape= (4,512,14,14)\r\n",
    "        self.relu52=nn.ReLU()\r\n",
    "        #Shape= (4,512,14,14)\r\n",
    "        \r\n",
    "        self.conv53=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (4,512,14,14)\r\n",
    "        self.bn53=nn.BatchNorm2d(num_features=512)\r\n",
    "        #Shape= (4,512,14,14)\r\n",
    "        self.relu53=nn.ReLU()\r\n",
    "        #Shape= (4,512,14,14)\r\n",
    "        \r\n",
    "        self.pool5=nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
    "        #Reduce the image size be factor 2\r\n",
    "        #Shape= (4,512,7,7)\r\n",
    "            \r\n",
    "        self.fcs = nn.Sequential(\r\n",
    "            nn.Linear(512 * 7 * 7, 4096),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.5),\r\n",
    "            nn.Linear(4096, 4096),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.5),\r\n",
    "            nn.Linear(4096, num_classes),\r\n",
    "        )\r\n",
    "        #Feed forwad function\r\n",
    "        \r\n",
    "    def forward(self,input):\r\n",
    "        output=self.conv11(input)\r\n",
    "        output=self.bn11(output)\r\n",
    "        output=self.relu11(output)\r\n",
    "\r\n",
    "        output=self.conv12(output)\r\n",
    "        output=self.bn12(output)\r\n",
    "        output=self.relu12(output)\r\n",
    "\r\n",
    "        output=self.pool1(output)\r\n",
    "\r\n",
    "        output=self.conv21(output)\r\n",
    "        output=self.bn21(output)\r\n",
    "        output=self.relu21(output)\r\n",
    "\r\n",
    "        output=self.conv22(output)\r\n",
    "        output=self.bn22(output)\r\n",
    "        output=self.relu22(output)\r\n",
    "\r\n",
    "        output=self.pool2(output)\r\n",
    "\r\n",
    "        output=self.conv31(output)\r\n",
    "        output=self.bn31(output)\r\n",
    "        output=self.relu31(output)\r\n",
    "        \r\n",
    "        output=self.conv32(output)\r\n",
    "        output=self.bn32(output)\r\n",
    "        output=self.relu32(output)\r\n",
    "\r\n",
    "        output=self.conv33(output)\r\n",
    "        output=self.bn33(output)\r\n",
    "        output=self.relu33(output)\r\n",
    "\r\n",
    "        output=self.pool3(output)\r\n",
    "\r\n",
    "        output=self.conv41(output)\r\n",
    "        output=self.bn41(output)\r\n",
    "        output=self.relu41(output)\r\n",
    "\r\n",
    "        output=self.conv42(output)\r\n",
    "        output=self.bn42(output)\r\n",
    "        output=self.relu42(output)\r\n",
    "\r\n",
    "        output=self.conv43(output)\r\n",
    "        output=self.bn43(output)\r\n",
    "        output=self.relu43(output)\r\n",
    "\r\n",
    "        output=self.pool4(output)\r\n",
    "\r\n",
    "        output=self.conv51(output)\r\n",
    "        output=self.bn51(output)\r\n",
    "        output=self.relu51(output)\r\n",
    "\r\n",
    "        output=self.conv52(output)\r\n",
    "        output=self.bn52(output)\r\n",
    "        output=self.relu52(output)\r\n",
    "\r\n",
    "        output=self.conv53(output)\r\n",
    "        output=self.bn53(output)\r\n",
    "        output=self.relu53(output)\r\n",
    "\r\n",
    "        output=self.pool5(output)\r\n",
    "\r\n",
    "        output = output.reshape(output.shape[0], -1)\r\n",
    "        output = self.fcs(output)\r\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "## AlexNet implementation\r\n",
    "\r\n",
    "class AlexNet(nn.Module):\r\n",
    "    \"\"\"\r\n",
    "    Neural network model consisting of layers propsed by AlexNet paper.\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, num_classes):\r\n",
    "        \"\"\"\r\n",
    "        Define and allocate layers for this neural net.\r\n",
    "        Args:\r\n",
    "            num_classes (int): number of classes to predict with this model\r\n",
    "        \"\"\"\r\n",
    "        super().__init__()\r\n",
    "        # input size should be : (b x 3 x 227 x 227)\r\n",
    "        # The image in the original paper states that width and height are 224 pixels, but\r\n",
    "        # the dimensions after first convolution layer do not lead to 55 x 55.\r\n",
    "        self.net = nn.Sequential(\r\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),  # (b x 96 x 55 x 55)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # section 3.3\r\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 96 x 27 x 27)\r\n",
    "            nn.Conv2d(96, 256, 5, padding=2),  # (b x 256 x 27 x 27)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\r\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 13 x 13)\r\n",
    "            nn.Conv2d(256, 384, 3, padding=1),  # (b x 384 x 13 x 13)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2d(384, 384, 3, padding=1),  # (b x 384 x 13 x 13)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2d(384, 256, 3, padding=1),  # (b x 256 x 13 x 13)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6)\r\n",
    "        )\r\n",
    "        # classifier is just a name for linear layers\r\n",
    "        self.classifier = nn.Sequential(\r\n",
    "            nn.Dropout(p=0.5, inplace=True),\r\n",
    "            nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.5, inplace=True),\r\n",
    "            nn.Linear(in_features=4096, out_features=4096),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(in_features=4096, out_features=num_classes),\r\n",
    "        )\r\n",
    "        self.init_bias()  # initialize bias\r\n",
    "\r\n",
    "    def init_bias(self):\r\n",
    "        for layer in self.net:\r\n",
    "            if isinstance(layer, nn.Conv2d):\r\n",
    "                nn.init.normal_(layer.weight, mean=0, std=0.01)\r\n",
    "                nn.init.constant_(layer.bias, 0)\r\n",
    "        # original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers\r\n",
    "        nn.init.constant_(self.net[4].bias, 1)\r\n",
    "        nn.init.constant_(self.net[10].bias, 1)\r\n",
    "        nn.init.constant_(self.net[12].bias, 1)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        \"\"\"\r\n",
    "        Pass the input through the net.\r\n",
    "        Args:\r\n",
    "            x (Tensor): input tensor\r\n",
    "        Returns:\r\n",
    "            output (Tensor): output tensor\r\n",
    "        \"\"\"\r\n",
    "        x = self.net(x)\r\n",
    "        x = x.view(-1, 256 * 6 * 6)  # reduce the dimensions for linear layer input\r\n",
    "        return self.classifier(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "## Le Net 5 implementation\r\n",
    "class LeNet(nn.Module):\r\n",
    "    def __init__(self, num_classes):\r\n",
    "        super(LeNet, self).__init__()\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\r\n",
    "        self.conv1 = nn.Conv2d(\r\n",
    "            in_channels=1,\r\n",
    "            out_channels=6,\r\n",
    "            kernel_size=(5, 5),\r\n",
    "            stride=(1, 1),\r\n",
    "            padding=(0, 0),\r\n",
    "        )\r\n",
    "        self.conv2 = nn.Conv2d(\r\n",
    "            in_channels=6,\r\n",
    "            out_channels=16,\r\n",
    "            kernel_size=(5, 5),\r\n",
    "            stride=(1, 1),\r\n",
    "            padding=(0, 0),\r\n",
    "        )\r\n",
    "        self.conv3 = nn.Conv2d(\r\n",
    "            in_channels=16,\r\n",
    "            out_channels=120,\r\n",
    "            kernel_size=(5, 5),\r\n",
    "            stride=(1, 1),\r\n",
    "            padding=(0, 0),\r\n",
    "        )\r\n",
    "        self.linear1 = nn.Linear(120, 84)\r\n",
    "        self.linear2 = nn.Linear(84, num_classes)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.relu(self.conv1(x))\r\n",
    "        x = self.pool(x)\r\n",
    "        x = self.relu(self.conv2(x))\r\n",
    "        x = self.pool(x)\r\n",
    "        x = self.relu(\r\n",
    "            self.conv3(x)\r\n",
    "        )  # num_examples x 120 x 1 x 1 --> num_examples x 120\r\n",
    "        x = x.reshape(x.shape[0], -1)\r\n",
    "        x = self.relu(self.linear1(x))\r\n",
    "        x = self.linear2(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "model=ConvNet(num_classes=len(classes)).to(device)\r\n",
    "\r\n",
    "# model = VGG_net(3, len(classes) , \"VGG16\").to(device)\r\n",
    "\r\n",
    "# model = MyVGG16(num_classes=len(classes)).to(device)\r\n",
    "\r\n",
    "# model = AlexNet(num_classes=len(classes)).to(device)\r\n",
    "\r\n",
    "# model = LeNet(num_classes=len(classes)).to(device)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#Optmizer and loss function\r\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\r\n",
    "loss_function=nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#calculating the size of training and testing images\r\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\r\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(train_count,test_count)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "500 100\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#Model training and saving best model\r\n",
    "\r\n",
    "best_accuracy=0.0\r\n",
    "\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    \r\n",
    "    #Evaluation and training on training dataset\r\n",
    "    model.train()\r\n",
    "    train_accuracy=0.0\r\n",
    "    train_loss=0.0\r\n",
    "    \r\n",
    "    for i, (images,labels) in enumerate(train_loader):\r\n",
    "        if torch.cuda.is_available():\r\n",
    "            images=Variable(images.cuda())\r\n",
    "            labels=Variable(labels.cuda())\r\n",
    "            \r\n",
    "        optimizer.zero_grad()\r\n",
    "        \r\n",
    "        outputs=model(images)\r\n",
    "        loss=loss_function(outputs,labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        \r\n",
    "        train_loss+= loss.cpu().data*images.size(0)\r\n",
    "        _,prediction=torch.max(outputs.data,1)\r\n",
    "        \r\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\r\n",
    "        \r\n",
    "    train_accuracy=train_accuracy/train_count\r\n",
    "    train_loss=train_loss/train_count\r\n",
    "    \r\n",
    "    \r\n",
    "    # Evaluation on testing dataset\r\n",
    "    model.eval()\r\n",
    "    \r\n",
    "    test_accuracy=0.0\r\n",
    "    for i, (images,labels) in enumerate(test_loader):\r\n",
    "        if torch.cuda.is_available():\r\n",
    "            images=Variable(images.cuda())\r\n",
    "            labels=Variable(labels.cuda())\r\n",
    "            \r\n",
    "        outputs=model(images)\r\n",
    "        _,prediction=torch.max(outputs.data,1)\r\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\r\n",
    "    \r\n",
    "    test_accuracy=test_accuracy/test_count\r\n",
    "    \r\n",
    "    \r\n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\r\n",
    "    \r\n",
    "    #Save the best model\r\n",
    "    if test_accuracy>best_accuracy:\r\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\r\n",
    "        best_accuracy=test_accuracy\r\n",
    "    \r\n",
    "       \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Vinit\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 6.00 GiB total capacity; 2.24 GiB already allocated; 1.54 GiB free; 2.25 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35256/1429805020.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 6.00 GiB total capacity; 2.24 GiB already allocated; 1.54 GiB free; 2.25 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "checkpoint = torch.load('best_checkpoint.model')\r\n",
    "model.load_state_dict(checkpoint)\r\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc): Linear(in_features=180000, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Transforms\r\n",
    "transformer=transforms.Compose([\r\n",
    "    transforms.Resize((150,150)),\r\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\r\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\r\n",
    "                        [0.5,0.5,0.5])\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Making predictions\r\n",
    "from PIL import Image\r\n",
    "from io import open\r\n",
    "\r\n",
    "\r\n",
    "def prediction(path, transform):\r\n",
    "    image=Image.open(path)\r\n",
    "    image_tensor=transformer(image).float()\r\n",
    "    image_tensor=image_tensor.unsqueeze_(0)\r\n",
    "    image_tensor=image_tensor.to(device)\r\n",
    "    output=model(image_tensor)\r\n",
    "    _,prediction=torch.max(output.data,1)\r\n",
    "    return classes[prediction[0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_path = \"Dataset\\\\test\"\r\n",
    "image_path=glob.glob(test_path+'/*.jpg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions={}\r\n",
    "for i,path in enumerate(image_path):\r\n",
    "    predictions[path[len(test_path)+1:]]=prediction(path,transformer)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'101.jpg': 'oil_well',\n",
       " '102.jpg': 'basketball_court',\n",
       " '103.jpg': 'crosswalk',\n",
       " '104.jpg': 'oil_well',\n",
       " '105.jpg': 'bridge',\n",
       " '106.jpg': 'railway',\n",
       " '107.jpg': 'tennis_court',\n",
       " '108.jpg': 'golf_course',\n",
       " '109.jpg': 'overpass',\n",
       " '110.jpg': 'overpass',\n",
       " '111.jpg': 'bridge',\n",
       " '112.jpg': 'basketball_court',\n",
       " '113.jpg': 'oil_well',\n",
       " '114.jpg': 'overpass',\n",
       " '115.jpg': 'runway',\n",
       " '116.jpg': 'swimming_pool',\n",
       " '117.jpg': 'basketball_court',\n",
       " '118.jpg': 'oil_well',\n",
       " '119.jpg': 'runway',\n",
       " '120.jpg': 'basketball_court',\n",
       " '121.jpg': 'oil_well',\n",
       " '122.jpg': 'overpass',\n",
       " '123.jpg': 'crosswalk',\n",
       " '124.jpg': 'golf_course',\n",
       " '125.jpg': 'crosswalk',\n",
       " '126.jpg': 'railway',\n",
       " '127.jpg': 'runway',\n",
       " '128.jpg': 'basketball_court',\n",
       " '129.jpg': 'oil_well',\n",
       " '130.jpg': 'crosswalk',\n",
       " '131.jpg': 'golf_course',\n",
       " '132.jpg': 'basketball_court',\n",
       " '133.jpg': 'crosswalk',\n",
       " '134.jpg': 'runway',\n",
       " '135.jpg': 'overpass',\n",
       " '136.jpg': 'golf_course',\n",
       " '137.jpg': 'crosswalk',\n",
       " '138.jpg': 'bridge',\n",
       " '139.jpg': 'overpass',\n",
       " '140.jpg': 'swimming_pool',\n",
       " '141.jpg': 'runway',\n",
       " '142.jpg': 'basketball_court',\n",
       " '143.jpg': 'basketball_court',\n",
       " '144.jpg': 'golf_course',\n",
       " '145.jpg': 'basketball_court',\n",
       " '146.jpg': 'golf_course',\n",
       " '147.jpg': 'tennis_court',\n",
       " '148.jpg': 'oil_well',\n",
       " '149.jpg': 'basketball_court',\n",
       " '150.jpg': 'crosswalk',\n",
       " '151.jpg': 'runway',\n",
       " '152.jpg': 'runway',\n",
       " '153.jpg': 'tennis_court',\n",
       " '154.jpg': 'crosswalk',\n",
       " '155.jpg': 'railway',\n",
       " '156.jpg': 'golf_course',\n",
       " '157.jpg': 'basketball_court',\n",
       " '158.jpg': 'crosswalk',\n",
       " '159.jpg': 'crosswalk',\n",
       " '160.jpg': 'bridge',\n",
       " '161.jpg': 'runway',\n",
       " '162.jpg': 'crosswalk',\n",
       " '163.jpg': 'crosswalk',\n",
       " '164.jpg': 'golf_course',\n",
       " '165.jpg': 'bridge',\n",
       " '166.jpg': 'golf_course',\n",
       " '167.jpg': 'runway',\n",
       " '168.jpg': 'swimming_pool',\n",
       " '169.jpg': 'golf_course',\n",
       " '170.jpg': 'tennis_court',\n",
       " '171.jpg': 'oil_well',\n",
       " '172.jpg': 'overpass',\n",
       " '173.jpg': 'swimming_pool',\n",
       " '174.jpg': 'bridge',\n",
       " '175.jpg': 'runway',\n",
       " '176.jpg': 'crosswalk',\n",
       " '177.jpg': 'railway',\n",
       " '178.jpg': 'railway',\n",
       " '179.jpg': 'crosswalk',\n",
       " '180.jpg': 'golf_course',\n",
       " '181.jpg': 'golf_course',\n",
       " '182.jpg': 'golf_course',\n",
       " '183.jpg': 'golf_course',\n",
       " '184.jpg': 'runway',\n",
       " '185.jpg': 'crosswalk',\n",
       " '186.jpg': 'runway',\n",
       " '187.jpg': 'basketball_court',\n",
       " '188.jpg': 'crosswalk',\n",
       " '189.jpg': 'oil_well',\n",
       " '190.jpg': 'crosswalk',\n",
       " '191.jpg': 'railway',\n",
       " '192.jpg': 'golf_course',\n",
       " '193.jpg': 'overpass',\n",
       " '194.jpg': 'swimming_pool',\n",
       " '195.jpg': 'bridge',\n",
       " '196.jpg': 'railway',\n",
       " '197.jpg': 'oil_well',\n",
       " '198.jpg': 'golf_course',\n",
       " '199.jpg': 'swimming_pool',\n",
       " '200.jpg': 'runway'}"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "label_dict = {\r\n",
    "    \"basketball_court\": 1, \r\n",
    "    \"bridge\":2, \r\n",
    "    \"crosswalk\":3, \r\n",
    "    \"golf_course\":4, \r\n",
    "    \"oil_well\":5, \r\n",
    "    \"overpass\":6, \r\n",
    "    \"railway\":7, \r\n",
    "    \"runway\":8, \r\n",
    "    \"swimming_pool\":9, \r\n",
    "    \"tennis_court\":10\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Convert the predictions to labels from label_dict\r\n",
    "predictions_labels={}\r\n",
    "for key,value in predictions.items():\r\n",
    "    predictions_labels[key]=label_dict[value]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'101.jpg': 5,\n",
       " '102.jpg': 1,\n",
       " '103.jpg': 3,\n",
       " '104.jpg': 5,\n",
       " '105.jpg': 2,\n",
       " '106.jpg': 7,\n",
       " '107.jpg': 10,\n",
       " '108.jpg': 4,\n",
       " '109.jpg': 6,\n",
       " '110.jpg': 6,\n",
       " '111.jpg': 2,\n",
       " '112.jpg': 1,\n",
       " '113.jpg': 5,\n",
       " '114.jpg': 6,\n",
       " '115.jpg': 8,\n",
       " '116.jpg': 9,\n",
       " '117.jpg': 1,\n",
       " '118.jpg': 5,\n",
       " '119.jpg': 8,\n",
       " '120.jpg': 1,\n",
       " '121.jpg': 5,\n",
       " '122.jpg': 6,\n",
       " '123.jpg': 3,\n",
       " '124.jpg': 4,\n",
       " '125.jpg': 3,\n",
       " '126.jpg': 7,\n",
       " '127.jpg': 8,\n",
       " '128.jpg': 1,\n",
       " '129.jpg': 5,\n",
       " '130.jpg': 3,\n",
       " '131.jpg': 4,\n",
       " '132.jpg': 1,\n",
       " '133.jpg': 3,\n",
       " '134.jpg': 8,\n",
       " '135.jpg': 6,\n",
       " '136.jpg': 4,\n",
       " '137.jpg': 3,\n",
       " '138.jpg': 2,\n",
       " '139.jpg': 6,\n",
       " '140.jpg': 9,\n",
       " '141.jpg': 8,\n",
       " '142.jpg': 1,\n",
       " '143.jpg': 1,\n",
       " '144.jpg': 4,\n",
       " '145.jpg': 1,\n",
       " '146.jpg': 4,\n",
       " '147.jpg': 10,\n",
       " '148.jpg': 5,\n",
       " '149.jpg': 1,\n",
       " '150.jpg': 3,\n",
       " '151.jpg': 8,\n",
       " '152.jpg': 8,\n",
       " '153.jpg': 10,\n",
       " '154.jpg': 3,\n",
       " '155.jpg': 7,\n",
       " '156.jpg': 4,\n",
       " '157.jpg': 1,\n",
       " '158.jpg': 3,\n",
       " '159.jpg': 3,\n",
       " '160.jpg': 2,\n",
       " '161.jpg': 8,\n",
       " '162.jpg': 3,\n",
       " '163.jpg': 3,\n",
       " '164.jpg': 4,\n",
       " '165.jpg': 2,\n",
       " '166.jpg': 4,\n",
       " '167.jpg': 8,\n",
       " '168.jpg': 9,\n",
       " '169.jpg': 4,\n",
       " '170.jpg': 10,\n",
       " '171.jpg': 5,\n",
       " '172.jpg': 6,\n",
       " '173.jpg': 9,\n",
       " '174.jpg': 2,\n",
       " '175.jpg': 8,\n",
       " '176.jpg': 3,\n",
       " '177.jpg': 7,\n",
       " '178.jpg': 7,\n",
       " '179.jpg': 3,\n",
       " '180.jpg': 4,\n",
       " '181.jpg': 4,\n",
       " '182.jpg': 4,\n",
       " '183.jpg': 4,\n",
       " '184.jpg': 8,\n",
       " '185.jpg': 3,\n",
       " '186.jpg': 8,\n",
       " '187.jpg': 1,\n",
       " '188.jpg': 3,\n",
       " '189.jpg': 5,\n",
       " '190.jpg': 3,\n",
       " '191.jpg': 7,\n",
       " '192.jpg': 4,\n",
       " '193.jpg': 6,\n",
       " '194.jpg': 9,\n",
       " '195.jpg': 2,\n",
       " '196.jpg': 7,\n",
       " '197.jpg': 5,\n",
       " '198.jpg': 4,\n",
       " '199.jpg': 9,\n",
       " '200.jpg': 8}"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting the predictions to CSV format"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert predictions to dataframe\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# Make a dataframe with the predictions with column names as ImageID and LabelID\r\n",
    "predictions_df = pd.DataFrame.from_dict(predictions_labels, orient='index')\r\n",
    "\r\n",
    "# Removing the .jpg from the file names\r\n",
    "predictions_df.index=predictions_df.index.str.replace('.jpg','')\r\n",
    "\r\n",
    "# Naming the columns as ImageID and Label\r\n",
    "predictions_df.reset_index(level=0, inplace=True)\r\n",
    "predictions_df.columns = ['ImageID', 'LabelID']\r\n",
    "\r\n",
    "# Removing the index from the dataframe\r\n",
    "predictions_df.reset_index(drop= True, inplace=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Vinit\\anaconda3\\envs\\gpu-pytorch\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>LabelID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>196</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>197</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>199</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageID  LabelID\n",
       "0      101        5\n",
       "1      102        1\n",
       "2      103        3\n",
       "3      104        5\n",
       "4      105        2\n",
       "..     ...      ...\n",
       "95     196        7\n",
       "96     197        5\n",
       "97     198        4\n",
       "98     199        9\n",
       "99     200        8\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Saving the predictions to csv\r\n",
    "predictions_df.to_csv('18D070067.csv',index=False)   #18D070067.csv is the name of the csv file and the index have been dropped"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hence, the implementation of the model is complete and the predictions are converted to CSV format."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('gpu-pytorch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "3d1484f6a5966aacf1d005944f88794f1e4469136ed9878e517c1d6594061a94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}